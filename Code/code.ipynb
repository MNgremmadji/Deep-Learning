{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Projet_Deep_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9XTOJDvuBx6g"
      },
      "source": [
        "# Projet Deep Learning : Pi-Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fV9viya8Bx6n"
      },
      "source": [
        "### Load the useful packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TQPwlPczBx6p",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r_bFPYwrBx6s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a462c63-417f-4116-9d67-735a78d8efe6"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6c54Dct1Bx64",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YitglKyvBx7B"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lLIpMPamBx7C",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wzzu5ijNBx7H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6820ad52-e32d-4481-c876-1b84a6af6c82"
      },
      "source": [
        "K.set_image_data_format('channels_last')\n",
        "(x_train_original, y_train_original), (x_test, y_test) = mnist.load_data()\n",
        "print('x_train shape:', x_train_original.shape)\n",
        "print(x_train_original.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NsVJ8J-3Bx7M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dab1692f-9d22-43f2-80a0-ec9f6dd21411"
      },
      "source": [
        "num_classes = y_train_original.max() +1\n",
        "num_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JPaC0reYBx7S"
      },
      "source": [
        "### Preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YZcGaAciBx7U"
      },
      "source": [
        "- Data cleaning\n",
        "- Data conversion\n",
        "- Data normalization\n",
        "- Data split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4Ayz9Mo7Bx7V"
      },
      "source": [
        "#### Data split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6kR-E9WSBx7W",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xz3-PhxpBx7b",
        "colab": {}
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train_original, y_train_original, test_size=1000, random_state=42, shuffle= True,stratify=y_train_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gHo6DlVuBx7f"
      },
      "source": [
        "#### Convert class vectors to binary class matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YHNGpoyLBx7i",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UnOMoynXBx7k",
        "colab": {}
      },
      "source": [
        "y_train_original = to_categorical(y_train_original, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_val = to_categorical(y_val, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4mhzGMuFBx7n"
      },
      "source": [
        "#### Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QisGQD7WBx7o",
        "colab": {}
      },
      "source": [
        "# The data must be converted into float in order to normalize them.\n",
        "x_train_original = x_train_original.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "\n",
        "x_train_original /= 255\n",
        "x_test /= 255\n",
        "x_train /= 255\n",
        "x_val /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yUO70ScQBx7t"
      },
      "source": [
        "### Adapt shapes and display digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iZWxlx44Bx7w",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9UD5ixR4Bx7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "744a6c31-e85f-41f3-9a6f-59dde72a8d1e"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "x_val = np.expand_dims(x_val, axis=-1)\n",
        "\n",
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59000, 28, 28)\n",
            "(59000, 10)\n",
            "(59000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VgGDZ8NzSaTI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f65a0ad4-25e7-44dd-f1e3-54cef9f7b74c"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59000, 28, 28, 1)\n",
            "(1000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ezsItNaHBx73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf76b2ec-7521-4f70-864f-1ec3f534b707"
      },
      "source": [
        "n_input =x_train.shape[1]*x_train.shape[2]\n",
        "n_hidden_1 = 128\n",
        "n_hidden_2 = 64\n",
        "n_classes = y_train.shape[1]\n",
        "n_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g1B-kl4SBx79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "709dfc64-9c1b-4f6a-e40c-c73ea955912d"
      },
      "source": [
        "plt.rcParams['figure.figsize']=(12,8)\n",
        "for k in range(9):\n",
        "    plt.subplot(3,3,k+1)\n",
        "    plt.imshow(x_train[k,:,:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnoAAAHTCAYAAACwUbW3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBwAAkFMs9AAAAHLq/wf9iE/xvSttsAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x576 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B1P8RULf4NQS",
        "colab": {}
      },
      "source": [
        "#Split the data in n_labels labeled samples and the rest as unlabeled \n",
        "def prepare_semi_data(x,y,n_labels):\n",
        "  idx = np.random.choice(range(np.shape(y)[0]),n_labels, replace=False)\n",
        "  y_label = np.array([y[k] for k in idx])\n",
        "  y_unlabel = np.array([y[k] for k in range(np.shape(y)[0]) if k not in idx])\n",
        "  x_label = np.array([x[k] for k in idx])\n",
        "  x_unlabel = np.array([x[k] for k in range(np.shape(y)[0]) if k not in idx])\n",
        "  return x_label,x_unlabel,y_label,y_unlabel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NbRZozAkKape",
        "colab": {}
      },
      "source": [
        "#Split of the dataset with n_labels=100 for 100 labeled samples\n",
        "x_label,x_unlabel,y_label,y_unlabel = prepare_semi_data(x_train,y_train,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TXVEHM6mBx8B"
      },
      "source": [
        "Definition of the architecture of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aCEtRf4LBx8B",
        "colab": {}
      },
      "source": [
        "#network architecture CNN definition (drop outs necessary for pi-model to work)\n",
        "def net(x,weights,biases,is_training,keep_prob):  \n",
        "\n",
        "    layer1 = tf.nn.conv2d(input=x,filter=weights['conv1w1'],strides=[1, 1, 1, 1], padding='SAME')\n",
        "    layer1 = tf.layers.batch_normalization(layer1,training=is_training)\n",
        "    layer1 = tf.nn.dropout(layer1, keep_prob)\n",
        "    layer1 = tf.nn.conv2d(input=layer1,filter=weights['conv1w2'],strides=[1, 2, 2, 1], padding='SAME')\n",
        "    layer1 = tf.layers.batch_normalization(layer1,training=is_training)\n",
        "    layer1 = tf.nn.leaky_relu(layer1,alpha=0.1)\n",
        "\n",
        "    layer2 = tf.nn.conv2d(input=layer1,filter=weights['conv2w1'],strides=[1, 1, 1, 1], padding='SAME')\n",
        "    layer2 = tf.layers.batch_normalization(layer2,training=is_training)\n",
        "    layer2 = tf.nn.dropout(layer2, keep_prob)\n",
        "    layer2 = tf.nn.conv2d(input=layer2,filter=weights['conv2w2'],strides=[1, 2, 2, 1], padding='SAME')\n",
        "    layer2 = tf.layers.batch_normalization(layer2,training=is_training)\n",
        "    layer2 = tf.nn.leaky_relu(layer2,alpha=0.1)\n",
        "    \n",
        "    layer_shape = layer2.get_shape()\n",
        "    num_features = layer_shape[1:4].num_elements()\n",
        "    layer_flat = tf.reshape(layer2, [-1, num_features])\n",
        "\n",
        "    fc1 = tf.add(tf.matmul(layer_flat, weights['fc1_w']), biases['fc1_b'])\n",
        "    fc1 = tf.layers.batch_normalization(fc1,training=is_training)\n",
        "    fc1 = tf.nn.leaky_relu(fc1,alpha=0.1, name='fc1')\n",
        "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
        "\n",
        "    output_layer = tf.add(tf.matmul(fc1, weights['out_w']), biases['out_b'],name='output')\n",
        "    return output_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NpL5btpYBx8D",
        "colab": {}
      },
      "source": [
        "def train(X_train_label, y_train_label, X_train_unlabel,X_test,y_test, display_step = 1,training_epochs = 30, batch_size = 128, semi=True):\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    \n",
        "    #Inputs of the model\n",
        "    X_label = tf.placeholder(tf.float32, shape=[None, X_train_label.shape[1], X_train_label.shape[2], X_train_label.shape[3]])\n",
        "    X_unlabel = tf.placeholder(tf.float32, shape=[None, X_train_label.shape[1], X_train_label.shape[2], X_train_label.shape[3]])\n",
        "    Y_label = tf.placeholder(tf.uint8, shape=[None, n_classes])\n",
        "    \n",
        "    #Hyperparameters\n",
        "    W = tf.placeholder(tf.float32,shape=None)\n",
        "\n",
        "    #Dropout train (p=0.5) and test time (p=1)\n",
        "    keep_prob = tf.placeholder(tf.float32)\n",
        "    keep_prob_v_training = 0.5\n",
        "\n",
        "    #Update parameters train (true) and test time (false)\n",
        "    is_training = tf.placeholder(tf.bool)\n",
        "\n",
        "    #Number of batches\n",
        "    total_batches=len(X_train_unlabel)//batch_size\n",
        "    \n",
        "    \n",
        "    #Parameters\n",
        "    weights = {\n",
        "        'conv1w1': tf.get_variable('Wc11', shape=[3, 3, 1, 32], initializer=tf.initializers.truncated_normal()),\n",
        "        'conv1w2': tf.get_variable('Wc12', shape=[5, 5, 32, 32], initializer=tf.initializers.truncated_normal()),\n",
        "        'conv2w1': tf.get_variable('Wc21', shape=[3, 3, 32, 64], initializer=tf.initializers.truncated_normal()),\n",
        "        'conv2w2': tf.get_variable('Wc22', shape=[3, 3, 64, 64], initializer=tf.initializers.truncated_normal()),\n",
        "        'fc1_w': tf.get_variable('W1', shape=(3136, 128), initializer=tf.initializers.truncated_normal()),\n",
        "        'out_w': tf.get_variable('W_out',shape=(128, 10), initializer=tf.initializers.truncated_normal())\n",
        "    }\n",
        "\n",
        "    biases = {\n",
        "        'fc1_b': tf.get_variable('B1',shape=(128),initializer=tf.keras.initializers.RandomNormal()),\n",
        "        'out_b': tf.get_variable('B_out',shape=(10),initializer=tf.keras.initializers.RandomNormal())\n",
        "    }\n",
        "    \n",
        "    #labeled data loss\n",
        "    pred_label = net(X_label,weights,biases,is_training,keep_prob)\n",
        "    pred_label_tild = net(X_label,weights,biases,is_training,keep_prob)\n",
        "    loss_cross = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred_label, labels=Y_label))\n",
        "    loss_label_sq =  tf.math.minimum(10*0.01,0.1*W*tf.reduce_mean((tf.nn.softmax(pred_label) - tf.nn.softmax(pred_label_tild))**2))\n",
        "    loss_label = loss_cross + loss_label_sq\n",
        "\n",
        "    #unlabeled data loss\n",
        "    pred_unlabel = net(X_unlabel,weights,biases,is_training,keep_prob)\n",
        "    pred_unlabel_tild = net(X_unlabel,weights,biases,is_training,keep_prob)\n",
        "    loss_unlabel_sq =  tf.math.minimum(10*0.01,0.1*W*tf.reduce_mean((tf.nn.softmax(pred_unlabel) - tf.nn.softmax(pred_unlabel_tild))**2))\n",
        "    loss_unlabel = loss_unlabel_sq\n",
        "\n",
        "    #Compute the average of the loss across all the dimensions\n",
        "    cost = tf.cond(is_training,lambda : loss_label + loss_unlabel, lambda : loss_label)\n",
        "\n",
        "    #optimizer\n",
        "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "        trainer = tf.train.AdamOptimizer()\n",
        "        optimizer = trainer.minimize(cost)\n",
        "        \n",
        "    correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(pred_label),1), tf.argmax(Y_label, 1))\n",
        "\n",
        "    #Calculate the accuracy across all the given batch and average them out. \n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "    config = tf.ConfigProto(log_device_placement=True,allow_soft_placement=True)\n",
        "    #config.gpu_options.allow_growth = True\n",
        "    \n",
        "    with tf.device(\"/gpu:0\"):\n",
        "        with tf.Session(config=config) as sess:\n",
        "            \n",
        "            sess.run(init) \n",
        "                \n",
        "            train_accuracy=[]\n",
        "            train_loss=[]\n",
        "            test_accuracy=[]\n",
        "            test_loss=[]         \n",
        "\n",
        "            for epoch in range(training_epochs):\n",
        "                avg_cost, avg_acc= 0,0\n",
        "                \n",
        "                if semi:\n",
        "                  #shuffle unlabel index\n",
        "                  index = np.arange(X_train_unlabel.shape[0])\n",
        "                  np.random.shuffle(index)\n",
        "                  batch_X_unlabel = np.array_split(X_train_unlabel[index], total_batches)\n",
        "\n",
        "                # rampup factor  setting\n",
        "                w = np.exp(-5*(1-epoch/80)**2)\n",
        "\n",
        "                for batch in range(total_batches):\n",
        "\n",
        "                    batch_x_unlabel = batch_X_unlabel[batch]\n",
        "\n",
        "                    #shuffle label index\n",
        "                    index = np.random.choice(np.arange(X_train_label.shape[0]),replace=False,size=batch_size//4)\n",
        "                    batch_X_label = X_train_label[index]\n",
        "                    batch_y_label = y_train_label[index]\n",
        "\n",
        "                    # Calculate batch loss and accuracy\n",
        "                    sess.run(optimizer, feed_dict={X_label: batch_X_label,Y_label: batch_y_label, X_unlabel:batch_x_unlabel, W:w,\n",
        "                                                           is_training:True,keep_prob:keep_prob_v_training})\n",
        "                # Calculate batch loss and accuracy after an epoch on the train and validation set\n",
        "                avg_cost,avg_acc = sess.run([cost, accuracy], feed_dict={X_label: batch_X_label,Y_label: batch_y_label, X_unlabel:batch_x_unlabel, W:w,\n",
        "                                                       is_training:False,keep_prob:1})\n",
        "                train_accuracy.append(avg_acc)\n",
        "                train_loss.append(avg_cost)\n",
        "\n",
        "                loss_test,acc_test = sess.run([cost, accuracy], \n",
        "                                                feed_dict={X_label: X_test,Y_label: y_test, X_unlabel:batch_x_unlabel, W:w,is_training:False,keep_prob:1})\n",
        "                test_accuracy.append(acc_test)\n",
        "                test_loss.append(loss_test)\n",
        "                \n",
        "                if (epoch % display_step == 0) or (epoch == (training_epochs-1)):\n",
        "                    print('| Epoch: {}/{} | Train: Loss {:.6f} Accuracy : {:.6f} '\\\n",
        "                    '| Test: Loss {:.6f} Accuracy : {:.6f}\\n'.format(\n",
        "                    epoch+1, training_epochs,avg_cost, avg_acc,loss_test,acc_test)) \n",
        "            \n",
        "            return {'train_accuracy':train_accuracy,'train_loss':train_loss,\n",
        "                    'test_accuracy':test_accuracy,'test_loss':test_loss}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2NEwG3NABx8F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d507d59-7723-47d5-914c-a8c9b4b0b622"
      },
      "source": [
        "result = train(X_train_label=x_label, y_train_label=y_label,X_train_unlabel=x_unlabel,X_test=x_val,y_test=y_val)\n",
        "plt.subplot(1,2,1)\n",
        "plt.grid(True)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(result['train_loss'], label='Training Loss', linestyle='--')\n",
        "plt.plot(result['test_loss'],  label='Test Loss',linestyle='--')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.grid(True)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(result['train_accuracy'], label='Training Accuracy', linestyle='--')\n",
        "plt.plot(result['test_accuracy'],  label='Test Accuracy', linestyle='--')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "| Epoch: 1/30 | Train: Loss 0.087025 Accuracy : 0.968750 | Test: Loss 1.594695 Accuracy : 0.701600\n",
            "\n",
            "| Epoch: 2/30 | Train: Loss 0.007943 Accuracy : 1.000000 | Test: Loss 1.385776 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 3/30 | Train: Loss 0.000057 Accuracy : 1.000000 | Test: Loss 1.335035 Accuracy : 0.767700\n",
            "\n",
            "| Epoch: 4/30 | Train: Loss 0.000004 Accuracy : 1.000000 | Test: Loss 1.337582 Accuracy : 0.779300\n",
            "\n",
            "| Epoch: 5/30 | Train: Loss 0.000110 Accuracy : 1.000000 | Test: Loss 1.361220 Accuracy : 0.780300\n",
            "\n",
            "| Epoch: 6/30 | Train: Loss 0.000044 Accuracy : 1.000000 | Test: Loss 1.370252 Accuracy : 0.783700\n",
            "\n",
            "| Epoch: 7/30 | Train: Loss 0.000020 Accuracy : 1.000000 | Test: Loss 1.383327 Accuracy : 0.785000\n",
            "\n",
            "| Epoch: 8/30 | Train: Loss 0.000003 Accuracy : 1.000000 | Test: Loss 1.389443 Accuracy : 0.788500\n",
            "\n",
            "| Epoch: 9/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.420369 Accuracy : 0.789600\n",
            "\n",
            "| Epoch: 10/30 | Train: Loss 0.000003 Accuracy : 1.000000 | Test: Loss 1.455453 Accuracy : 0.786200\n",
            "\n",
            "| Epoch: 11/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.482395 Accuracy : 0.786400\n",
            "\n",
            "| Epoch: 12/30 | Train: Loss 0.000001 Accuracy : 1.000000 | Test: Loss 1.484885 Accuracy : 0.787200\n",
            "\n",
            "| Epoch: 13/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.516183 Accuracy : 0.785400\n",
            "\n",
            "| Epoch: 14/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.523666 Accuracy : 0.790200\n",
            "\n",
            "| Epoch: 15/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.550242 Accuracy : 0.786400\n",
            "\n",
            "| Epoch: 16/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.549363 Accuracy : 0.790300\n",
            "\n",
            "| Epoch: 17/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.571753 Accuracy : 0.791700\n",
            "\n",
            "| Epoch: 18/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.609256 Accuracy : 0.788500\n",
            "\n",
            "| Epoch: 19/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.640889 Accuracy : 0.790200\n",
            "\n",
            "| Epoch: 20/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.639169 Accuracy : 0.788800\n",
            "\n",
            "| Epoch: 21/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.652450 Accuracy : 0.788200\n",
            "\n",
            "| Epoch: 22/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.620661 Accuracy : 0.793500\n",
            "\n",
            "| Epoch: 23/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.694101 Accuracy : 0.792800\n",
            "\n",
            "| Epoch: 24/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.729717 Accuracy : 0.789300\n",
            "\n",
            "| Epoch: 25/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.755012 Accuracy : 0.792500\n",
            "\n",
            "| Epoch: 26/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.827976 Accuracy : 0.786200\n",
            "\n",
            "| Epoch: 27/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.779906 Accuracy : 0.791900\n",
            "\n",
            "| Epoch: 28/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.775944 Accuracy : 0.792800\n",
            "\n",
            "| Epoch: 29/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.774348 Accuracy : 0.792500\n",
            "\n",
            "| Epoch: 30/30 | Train: Loss 0.000000 Accuracy : 1.000000 | Test: Loss 1.760851 Accuracy : 0.793200\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f57e301e0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtkAAAHgCAYAAABw0HFmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU5EtIiIiIlLL/j/g+1wDYjr+xgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ijmegvi9Bx8I"
      },
      "source": [
        "#### Underlying CNN architecture trained in supervised learning with 100 labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Yus9weCQ9It",
        "colab": {}
      },
      "source": [
        "def net_superv(x,weights,biases,is_training,keep_prob):  \n",
        "    \n",
        "    layer1 = tf.nn.conv2d(input=x,filter=weights['conv1w1'],strides=[1, 1, 1, 1], padding='SAME')\n",
        "    layer1 = tf.layers.batch_normalization(layer1,training=is_training)\n",
        "    layer1 = tf.nn.dropout(layer1, keep_prob)\n",
        "    layer1 = tf.nn.conv2d(input=layer1,filter=weights['conv1w2'],strides=[1, 2, 2, 1], padding='SAME')\n",
        "    layer1 = tf.layers.batch_normalization(layer1,training=is_training)\n",
        "    layer1 = tf.nn.leaky_relu(layer1,alpha=0.1)\n",
        "\n",
        "    layer2 = tf.nn.conv2d(input=layer1,filter=weights['conv2w1'],strides=[1, 1, 1, 1], padding='SAME')\n",
        "    layer2 = tf.layers.batch_normalization(layer2,training=is_training)\n",
        "    layer2 = tf.nn.dropout(layer2, keep_prob)\n",
        "    layer2 = tf.nn.conv2d(input=layer2,filter=weights['conv2w2'],strides=[1, 2, 2, 1], padding='SAME')\n",
        "    layer2 = tf.layers.batch_normalization(layer2,training=is_training)\n",
        "    layer2 = tf.nn.leaky_relu(layer2,alpha=0.1)\n",
        "    \n",
        "    layer_shape = layer2.get_shape()\n",
        "    num_features = layer_shape[1:4].num_elements()\n",
        "    layer_flat = tf.reshape(layer2, [-1, num_features])\n",
        "\n",
        "\n",
        "    fc1 = tf.add(tf.matmul(layer_flat, weights['fc1_w']), biases['fc1_b'])\n",
        "    fc1 = tf.layers.batch_normalization(fc1,training=is_training)\n",
        "    fc1 = tf.nn.leaky_relu(fc1,alpha=0.1, name='fc1')\n",
        "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
        "    \n",
        "    output_layer = tf.add(tf.matmul(fc1, weights['out_w']), biases['out_b'],name='output')\n",
        "    return output_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j-ErvKWwQ9XR",
        "colab": {}
      },
      "source": [
        "def train_superv(X_train, y_train,X_test,y_test, display_step = 1,training_epochs = 1000, batch_size = 32):\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    \n",
        "    #Inputs of the model\n",
        "    X = tf.placeholder(tf.float32, shape=[None, X_train.shape[1], X_train.shape[2], X_train.shape[3]])\n",
        "    Y = tf.placeholder(tf.uint8, shape=[None, n_classes])\n",
        "\n",
        "    #Hyperparameters\n",
        "    keep_prob = tf.placeholder(tf.float32) #Dropout train (p=0.5) and test time (p=0.5)\n",
        "    is_training = tf.placeholder(tf.bool) #BatchNormalization train (true) and test time (false)\n",
        "    total_batches=len(X_train)//batch_size\n",
        "    keep_prob_v_training = 0.5\n",
        "    \n",
        "    #Parameters\n",
        "    weights = {\n",
        "        'conv1w1': tf.get_variable('Wc11', shape=[3, 3, 1, 32], initializer=tf.initializers.truncated_normal()),\n",
        "        'conv1w2': tf.get_variable('Wc12', shape=[5, 5, 32, 32], initializer=tf.initializers.truncated_normal()),\n",
        "        'conv2w1': tf.get_variable('Wc21', shape=[3, 3, 32, 64], initializer=tf.initializers.truncated_normal()),\n",
        "        'conv2w2': tf.get_variable('Wc22', shape=[3, 3, 64, 64], initializer=tf.initializers.truncated_normal()),\n",
        "        'fc1_w': tf.get_variable('W1', shape=(3136, 128), initializer=tf.initializers.truncated_normal()),\n",
        "        'out_w': tf.get_variable('W_out',shape=(128, 10), initializer=tf.initializers.truncated_normal())\n",
        "    }\n",
        "\n",
        "    biases = {\n",
        "        'fc1_b': tf.get_variable('B1',shape=(128),initializer=tf.keras.initializers.RandomNormal()),\n",
        "        'out_b': tf.get_variable('B_out',shape=(10),initializer=tf.keras.initializers.RandomNormal())\n",
        "    }\n",
        "    \n",
        "    pred = net_superv(X,weights,biases,is_training,keep_prob)\n",
        "\n",
        "    #Compute the average of the loss across all the dimensions\n",
        "    supervised = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=Y))\n",
        "    \n",
        "    cost = supervised\n",
        "\n",
        "    #optimizer\n",
        "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "        trainer = tf.train.AdamOptimizer()\n",
        "        optimizer = trainer.minimize(cost)\n",
        "        \n",
        "    correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(Y, 1))\n",
        "\n",
        "    #Calculate the accuracy across all the given batch and average them out. \n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "    config = tf.ConfigProto(log_device_placement=True,allow_soft_placement=True)\n",
        "    \n",
        "    with tf.device(\"/gpu:0\"):\n",
        "        with tf.Session(config=config) as sess:\n",
        "            \n",
        "            sess.run(init) \n",
        "              \n",
        "            train_accuracy=[]\n",
        "            train_loss=[]\n",
        "            test_accuracy=[]\n",
        "            test_loss=[]         \n",
        "\n",
        "            for epoch in range(training_epochs):\n",
        "                avg_cost, avg_acc= 0,0\n",
        "                \n",
        "#                 Shuffling the index\n",
        "                index = np.arange(X_train.shape[0])\n",
        "                np.random.shuffle(index)\n",
        "                batch_X = np.array_split(X_train[index], total_batches)\n",
        "                batch_Y = np.array_split(y_train[index], total_batches)\n",
        "                \n",
        "                for batch in range(total_batches):\n",
        "\n",
        "                    batch_x,batch_y=batch_X[batch],batch_Y[batch]\n",
        "                    sess.run(optimizer, feed_dict={X: batch_x,Y: batch_y,\n",
        "                                                           is_training:True,keep_prob:keep_prob_v_training})\n",
        "                    \n",
        "                # Calculate batch loss and accuracy after an epoch on the train and validation set\n",
        "                \n",
        "                avg_cost,avg_acc = sess.run([cost, accuracy], feed_dict={X: X_train,Y: y_train, \n",
        "                                                       is_training:False,keep_prob:1})\n",
        "                train_accuracy.append(avg_acc)\n",
        "                train_loss.append(avg_cost)\n",
        "\n",
        "                loss_test,acc_test = sess.run([cost, accuracy], \n",
        "                                                feed_dict={X: X_test,Y: y_test,is_training:False,keep_prob:1})\n",
        "                test_accuracy.append(acc_test)\n",
        "                test_loss.append(loss_test)\n",
        "        \n",
        "                if (epoch % display_step == 0) or (epoch == (training_epochs-1)):\n",
        "                    print('| Epoch: {}/{} | Train: Loss {:.6f} Accuracy : {:.6f} '\\\n",
        "                    '| Test: Loss {:.6f} Accuracy : {:.6f}\\n'.format(\n",
        "                    epoch+1, training_epochs,avg_cost, avg_acc,loss_test,acc_test)) \n",
        "            \n",
        "            return {'train_accuracy':train_accuracy,'train_loss':train_loss,\n",
        "                    'test_accuracy':test_accuracy,'test_loss':test_loss}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Akq2vrOAQ9Uo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d795cb6-e7d0-464f-d258-c4d28282d7db"
      },
      "source": [
        "result = train_superv(X_train=x_label, y_train=y_label,X_test=x_val,y_test=y_val)\n",
        "plt.subplot(1,2,1)\n",
        "plt.grid(True)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(result['train_loss'], label='Training Loss', linestyle='--')\n",
        "plt.plot(result['test_loss'],  label='Test Loss',linestyle='--')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.grid(True)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(result['train_accuracy'], label='Training Accuracy', linestyle='--')\n",
        "plt.plot(result['test_accuracy'],  label='Test Accuracy', linestyle='--')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "| Epoch: 1/1000 | Train: Loss 5270.312988 Accuracy : 0.110000 | Test: Loss 5001.853516 Accuracy : 0.106000\n",
            "\n",
            "| Epoch: 2/1000 | Train: Loss 1441.747681 Accuracy : 0.110000 | Test: Loss 1391.274536 Accuracy : 0.110000\n",
            "\n",
            "| Epoch: 3/1000 | Train: Loss 654.272705 Accuracy : 0.110000 | Test: Loss 638.812012 Accuracy : 0.111000\n",
            "\n",
            "| Epoch: 4/1000 | Train: Loss 373.732727 Accuracy : 0.110000 | Test: Loss 369.698486 Accuracy : 0.113000\n",
            "\n",
            "| Epoch: 5/1000 | Train: Loss 237.179214 Accuracy : 0.130000 | Test: Loss 237.997299 Accuracy : 0.116000\n",
            "\n",
            "| Epoch: 6/1000 | Train: Loss 163.325912 Accuracy : 0.130000 | Test: Loss 166.351608 Accuracy : 0.116000\n",
            "\n",
            "| Epoch: 7/1000 | Train: Loss 119.501389 Accuracy : 0.130000 | Test: Loss 123.528984 Accuracy : 0.119000\n",
            "\n",
            "| Epoch: 8/1000 | Train: Loss 90.310974 Accuracy : 0.140000 | Test: Loss 94.851738 Accuracy : 0.129000\n",
            "\n",
            "| Epoch: 9/1000 | Train: Loss 70.475853 Accuracy : 0.150000 | Test: Loss 75.404861 Accuracy : 0.133000\n",
            "\n",
            "| Epoch: 10/1000 | Train: Loss 56.074394 Accuracy : 0.150000 | Test: Loss 60.969559 Accuracy : 0.137000\n",
            "\n",
            "| Epoch: 11/1000 | Train: Loss 45.808605 Accuracy : 0.150000 | Test: Loss 50.775532 Accuracy : 0.143000\n",
            "\n",
            "| Epoch: 12/1000 | Train: Loss 37.673225 Accuracy : 0.150000 | Test: Loss 42.756611 Accuracy : 0.155000\n",
            "\n",
            "| Epoch: 13/1000 | Train: Loss 31.127886 Accuracy : 0.170000 | Test: Loss 36.288269 Accuracy : 0.161000\n",
            "\n",
            "| Epoch: 14/1000 | Train: Loss 25.943420 Accuracy : 0.200000 | Test: Loss 30.992559 Accuracy : 0.170000\n",
            "\n",
            "| Epoch: 15/1000 | Train: Loss 21.757236 Accuracy : 0.230000 | Test: Loss 26.640137 Accuracy : 0.179000\n",
            "\n",
            "| Epoch: 16/1000 | Train: Loss 18.341625 Accuracy : 0.250000 | Test: Loss 23.103123 Accuracy : 0.191000\n",
            "\n",
            "| Epoch: 17/1000 | Train: Loss 15.527245 Accuracy : 0.270000 | Test: Loss 20.169931 Accuracy : 0.207000\n",
            "\n",
            "| Epoch: 18/1000 | Train: Loss 13.274289 Accuracy : 0.300000 | Test: Loss 17.771097 Accuracy : 0.224000\n",
            "\n",
            "| Epoch: 19/1000 | Train: Loss 11.434885 Accuracy : 0.340000 | Test: Loss 15.763134 Accuracy : 0.233000\n",
            "\n",
            "| Epoch: 20/1000 | Train: Loss 9.950075 Accuracy : 0.340000 | Test: Loss 14.141120 Accuracy : 0.240000\n",
            "\n",
            "| Epoch: 21/1000 | Train: Loss 8.714186 Accuracy : 0.340000 | Test: Loss 12.767144 Accuracy : 0.253000\n",
            "\n",
            "| Epoch: 22/1000 | Train: Loss 7.725599 Accuracy : 0.380000 | Test: Loss 11.631742 Accuracy : 0.269000\n",
            "\n",
            "| Epoch: 23/1000 | Train: Loss 6.856607 Accuracy : 0.400000 | Test: Loss 10.638088 Accuracy : 0.284000\n",
            "\n",
            "| Epoch: 24/1000 | Train: Loss 6.074510 Accuracy : 0.430000 | Test: Loss 9.731770 Accuracy : 0.300000\n",
            "\n",
            "| Epoch: 25/1000 | Train: Loss 5.416179 Accuracy : 0.460000 | Test: Loss 8.957248 Accuracy : 0.312000\n",
            "\n",
            "| Epoch: 26/1000 | Train: Loss 4.871417 Accuracy : 0.490000 | Test: Loss 8.291706 Accuracy : 0.334000\n",
            "\n",
            "| Epoch: 27/1000 | Train: Loss 4.407874 Accuracy : 0.500000 | Test: Loss 7.694434 Accuracy : 0.348000\n",
            "\n",
            "| Epoch: 28/1000 | Train: Loss 4.021073 Accuracy : 0.500000 | Test: Loss 7.190093 Accuracy : 0.364000\n",
            "\n",
            "| Epoch: 29/1000 | Train: Loss 3.684716 Accuracy : 0.530000 | Test: Loss 6.761575 Accuracy : 0.382000\n",
            "\n",
            "| Epoch: 30/1000 | Train: Loss 3.396905 Accuracy : 0.580000 | Test: Loss 6.381325 Accuracy : 0.394000\n",
            "\n",
            "| Epoch: 31/1000 | Train: Loss 3.135139 Accuracy : 0.580000 | Test: Loss 6.032346 Accuracy : 0.405000\n",
            "\n",
            "| Epoch: 32/1000 | Train: Loss 2.909017 Accuracy : 0.610000 | Test: Loss 5.725427 Accuracy : 0.417000\n",
            "\n",
            "| Epoch: 33/1000 | Train: Loss 2.718743 Accuracy : 0.640000 | Test: Loss 5.462786 Accuracy : 0.432000\n",
            "\n",
            "| Epoch: 34/1000 | Train: Loss 2.546032 Accuracy : 0.640000 | Test: Loss 5.229174 Accuracy : 0.441000\n",
            "\n",
            "| Epoch: 35/1000 | Train: Loss 2.395214 Accuracy : 0.650000 | Test: Loss 5.026637 Accuracy : 0.451000\n",
            "\n",
            "| Epoch: 36/1000 | Train: Loss 2.264194 Accuracy : 0.650000 | Test: Loss 4.857864 Accuracy : 0.461000\n",
            "\n",
            "| Epoch: 37/1000 | Train: Loss 2.142885 Accuracy : 0.660000 | Test: Loss 4.686734 Accuracy : 0.471000\n",
            "\n",
            "| Epoch: 38/1000 | Train: Loss 2.031863 Accuracy : 0.660000 | Test: Loss 4.534477 Accuracy : 0.479000\n",
            "\n",
            "| Epoch: 39/1000 | Train: Loss 1.929855 Accuracy : 0.680000 | Test: Loss 4.400440 Accuracy : 0.487000\n",
            "\n",
            "| Epoch: 40/1000 | Train: Loss 1.842078 Accuracy : 0.690000 | Test: Loss 4.288388 Accuracy : 0.497000\n",
            "\n",
            "| Epoch: 41/1000 | Train: Loss 1.761365 Accuracy : 0.710000 | Test: Loss 4.181004 Accuracy : 0.501000\n",
            "\n",
            "| Epoch: 42/1000 | Train: Loss 1.689003 Accuracy : 0.730000 | Test: Loss 4.088226 Accuracy : 0.501000\n",
            "\n",
            "| Epoch: 43/1000 | Train: Loss 1.633648 Accuracy : 0.730000 | Test: Loss 4.005512 Accuracy : 0.509000\n",
            "\n",
            "| Epoch: 44/1000 | Train: Loss 1.580441 Accuracy : 0.750000 | Test: Loss 3.925532 Accuracy : 0.510000\n",
            "\n",
            "| Epoch: 45/1000 | Train: Loss 1.530438 Accuracy : 0.750000 | Test: Loss 3.859558 Accuracy : 0.519000\n",
            "\n",
            "| Epoch: 46/1000 | Train: Loss 1.485117 Accuracy : 0.730000 | Test: Loss 3.785176 Accuracy : 0.518000\n",
            "\n",
            "| Epoch: 47/1000 | Train: Loss 1.436628 Accuracy : 0.730000 | Test: Loss 3.714809 Accuracy : 0.520000\n",
            "\n",
            "| Epoch: 48/1000 | Train: Loss 1.393654 Accuracy : 0.730000 | Test: Loss 3.655926 Accuracy : 0.527000\n",
            "\n",
            "| Epoch: 49/1000 | Train: Loss 1.352156 Accuracy : 0.730000 | Test: Loss 3.589780 Accuracy : 0.529000\n",
            "\n",
            "| Epoch: 50/1000 | Train: Loss 1.311934 Accuracy : 0.730000 | Test: Loss 3.534695 Accuracy : 0.532000\n",
            "\n",
            "| Epoch: 51/1000 | Train: Loss 1.275717 Accuracy : 0.740000 | Test: Loss 3.476689 Accuracy : 0.537000\n",
            "\n",
            "| Epoch: 52/1000 | Train: Loss 1.236229 Accuracy : 0.750000 | Test: Loss 3.409312 Accuracy : 0.541000\n",
            "\n",
            "| Epoch: 53/1000 | Train: Loss 1.202507 Accuracy : 0.780000 | Test: Loss 3.364462 Accuracy : 0.540000\n",
            "\n",
            "| Epoch: 54/1000 | Train: Loss 1.164350 Accuracy : 0.780000 | Test: Loss 3.314154 Accuracy : 0.546000\n",
            "\n",
            "| Epoch: 55/1000 | Train: Loss 1.124813 Accuracy : 0.780000 | Test: Loss 3.262681 Accuracy : 0.546000\n",
            "\n",
            "| Epoch: 56/1000 | Train: Loss 1.088478 Accuracy : 0.780000 | Test: Loss 3.203833 Accuracy : 0.545000\n",
            "\n",
            "| Epoch: 57/1000 | Train: Loss 1.055650 Accuracy : 0.780000 | Test: Loss 3.159571 Accuracy : 0.548000\n",
            "\n",
            "| Epoch: 58/1000 | Train: Loss 1.029568 Accuracy : 0.790000 | Test: Loss 3.121030 Accuracy : 0.552000\n",
            "\n",
            "| Epoch: 59/1000 | Train: Loss 1.002220 Accuracy : 0.790000 | Test: Loss 3.082736 Accuracy : 0.551000\n",
            "\n",
            "| Epoch: 60/1000 | Train: Loss 0.976155 Accuracy : 0.790000 | Test: Loss 3.045728 Accuracy : 0.552000\n",
            "\n",
            "| Epoch: 61/1000 | Train: Loss 0.958723 Accuracy : 0.790000 | Test: Loss 3.018909 Accuracy : 0.554000\n",
            "\n",
            "| Epoch: 62/1000 | Train: Loss 0.942189 Accuracy : 0.790000 | Test: Loss 2.992365 Accuracy : 0.554000\n",
            "\n",
            "| Epoch: 63/1000 | Train: Loss 0.927884 Accuracy : 0.790000 | Test: Loss 2.974202 Accuracy : 0.556000\n",
            "\n",
            "| Epoch: 64/1000 | Train: Loss 0.912892 Accuracy : 0.800000 | Test: Loss 2.963659 Accuracy : 0.554000\n",
            "\n",
            "| Epoch: 65/1000 | Train: Loss 0.895662 Accuracy : 0.800000 | Test: Loss 2.948556 Accuracy : 0.555000\n",
            "\n",
            "| Epoch: 66/1000 | Train: Loss 0.872310 Accuracy : 0.800000 | Test: Loss 2.930177 Accuracy : 0.560000\n",
            "\n",
            "| Epoch: 67/1000 | Train: Loss 0.842579 Accuracy : 0.800000 | Test: Loss 2.902049 Accuracy : 0.568000\n",
            "\n",
            "| Epoch: 68/1000 | Train: Loss 0.818702 Accuracy : 0.800000 | Test: Loss 2.889939 Accuracy : 0.566000\n",
            "\n",
            "| Epoch: 69/1000 | Train: Loss 0.790246 Accuracy : 0.800000 | Test: Loss 2.864888 Accuracy : 0.566000\n",
            "\n",
            "| Epoch: 70/1000 | Train: Loss 0.767208 Accuracy : 0.800000 | Test: Loss 2.839557 Accuracy : 0.570000\n",
            "\n",
            "| Epoch: 71/1000 | Train: Loss 0.746931 Accuracy : 0.810000 | Test: Loss 2.819453 Accuracy : 0.571000\n",
            "\n",
            "| Epoch: 72/1000 | Train: Loss 0.727023 Accuracy : 0.810000 | Test: Loss 2.796589 Accuracy : 0.573000\n",
            "\n",
            "| Epoch: 73/1000 | Train: Loss 0.706491 Accuracy : 0.810000 | Test: Loss 2.771466 Accuracy : 0.575000\n",
            "\n",
            "| Epoch: 74/1000 | Train: Loss 0.683653 Accuracy : 0.820000 | Test: Loss 2.748657 Accuracy : 0.579000\n",
            "\n",
            "| Epoch: 75/1000 | Train: Loss 0.658147 Accuracy : 0.820000 | Test: Loss 2.719283 Accuracy : 0.579000\n",
            "\n",
            "| Epoch: 76/1000 | Train: Loss 0.637361 Accuracy : 0.830000 | Test: Loss 2.690982 Accuracy : 0.583000\n",
            "\n",
            "| Epoch: 77/1000 | Train: Loss 0.612402 Accuracy : 0.830000 | Test: Loss 2.661632 Accuracy : 0.586000\n",
            "\n",
            "| Epoch: 78/1000 | Train: Loss 0.594926 Accuracy : 0.830000 | Test: Loss 2.639307 Accuracy : 0.587000\n",
            "\n",
            "| Epoch: 79/1000 | Train: Loss 0.574617 Accuracy : 0.830000 | Test: Loss 2.613179 Accuracy : 0.590000\n",
            "\n",
            "| Epoch: 80/1000 | Train: Loss 0.558596 Accuracy : 0.840000 | Test: Loss 2.591851 Accuracy : 0.593000\n",
            "\n",
            "| Epoch: 81/1000 | Train: Loss 0.546694 Accuracy : 0.840000 | Test: Loss 2.574258 Accuracy : 0.596000\n",
            "\n",
            "| Epoch: 82/1000 | Train: Loss 0.537993 Accuracy : 0.840000 | Test: Loss 2.566242 Accuracy : 0.595000\n",
            "\n",
            "| Epoch: 83/1000 | Train: Loss 0.523932 Accuracy : 0.840000 | Test: Loss 2.549152 Accuracy : 0.595000\n",
            "\n",
            "| Epoch: 84/1000 | Train: Loss 0.508837 Accuracy : 0.840000 | Test: Loss 2.529121 Accuracy : 0.596000\n",
            "\n",
            "| Epoch: 85/1000 | Train: Loss 0.494083 Accuracy : 0.840000 | Test: Loss 2.506684 Accuracy : 0.595000\n",
            "\n",
            "| Epoch: 86/1000 | Train: Loss 0.482969 Accuracy : 0.840000 | Test: Loss 2.491076 Accuracy : 0.595000\n",
            "\n",
            "| Epoch: 87/1000 | Train: Loss 0.468615 Accuracy : 0.840000 | Test: Loss 2.470388 Accuracy : 0.598000\n",
            "\n",
            "| Epoch: 88/1000 | Train: Loss 0.456449 Accuracy : 0.840000 | Test: Loss 2.458170 Accuracy : 0.599000\n",
            "\n",
            "| Epoch: 89/1000 | Train: Loss 0.445468 Accuracy : 0.850000 | Test: Loss 2.444966 Accuracy : 0.602000\n",
            "\n",
            "| Epoch: 90/1000 | Train: Loss 0.433823 Accuracy : 0.850000 | Test: Loss 2.432675 Accuracy : 0.606000\n",
            "\n",
            "| Epoch: 91/1000 | Train: Loss 0.421191 Accuracy : 0.870000 | Test: Loss 2.413447 Accuracy : 0.608000\n",
            "\n",
            "| Epoch: 92/1000 | Train: Loss 0.410864 Accuracy : 0.870000 | Test: Loss 2.399398 Accuracy : 0.613000\n",
            "\n",
            "| Epoch: 93/1000 | Train: Loss 0.401188 Accuracy : 0.880000 | Test: Loss 2.389582 Accuracy : 0.613000\n",
            "\n",
            "| Epoch: 94/1000 | Train: Loss 0.392665 Accuracy : 0.890000 | Test: Loss 2.378964 Accuracy : 0.615000\n",
            "\n",
            "| Epoch: 95/1000 | Train: Loss 0.384594 Accuracy : 0.890000 | Test: Loss 2.370011 Accuracy : 0.614000\n",
            "\n",
            "| Epoch: 96/1000 | Train: Loss 0.375805 Accuracy : 0.900000 | Test: Loss 2.356772 Accuracy : 0.616000\n",
            "\n",
            "| Epoch: 97/1000 | Train: Loss 0.366495 Accuracy : 0.900000 | Test: Loss 2.341189 Accuracy : 0.617000\n",
            "\n",
            "| Epoch: 98/1000 | Train: Loss 0.357942 Accuracy : 0.900000 | Test: Loss 2.327199 Accuracy : 0.619000\n",
            "\n",
            "| Epoch: 99/1000 | Train: Loss 0.351293 Accuracy : 0.910000 | Test: Loss 2.314352 Accuracy : 0.618000\n",
            "\n",
            "| Epoch: 100/1000 | Train: Loss 0.341581 Accuracy : 0.910000 | Test: Loss 2.294858 Accuracy : 0.624000\n",
            "\n",
            "| Epoch: 101/1000 | Train: Loss 0.335767 Accuracy : 0.920000 | Test: Loss 2.285702 Accuracy : 0.628000\n",
            "\n",
            "| Epoch: 102/1000 | Train: Loss 0.327609 Accuracy : 0.920000 | Test: Loss 2.269501 Accuracy : 0.630000\n",
            "\n",
            "| Epoch: 103/1000 | Train: Loss 0.318240 Accuracy : 0.920000 | Test: Loss 2.253132 Accuracy : 0.635000\n",
            "\n",
            "| Epoch: 104/1000 | Train: Loss 0.309973 Accuracy : 0.920000 | Test: Loss 2.238690 Accuracy : 0.639000\n",
            "\n",
            "| Epoch: 105/1000 | Train: Loss 0.304345 Accuracy : 0.930000 | Test: Loss 2.231506 Accuracy : 0.641000\n",
            "\n",
            "| Epoch: 106/1000 | Train: Loss 0.299192 Accuracy : 0.930000 | Test: Loss 2.223311 Accuracy : 0.643000\n",
            "\n",
            "| Epoch: 107/1000 | Train: Loss 0.290606 Accuracy : 0.930000 | Test: Loss 2.206516 Accuracy : 0.644000\n",
            "\n",
            "| Epoch: 108/1000 | Train: Loss 0.281873 Accuracy : 0.930000 | Test: Loss 2.187422 Accuracy : 0.647000\n",
            "\n",
            "| Epoch: 109/1000 | Train: Loss 0.276138 Accuracy : 0.930000 | Test: Loss 2.173670 Accuracy : 0.647000\n",
            "\n",
            "| Epoch: 110/1000 | Train: Loss 0.270759 Accuracy : 0.930000 | Test: Loss 2.163069 Accuracy : 0.649000\n",
            "\n",
            "| Epoch: 111/1000 | Train: Loss 0.264396 Accuracy : 0.930000 | Test: Loss 2.152131 Accuracy : 0.648000\n",
            "\n",
            "| Epoch: 112/1000 | Train: Loss 0.255791 Accuracy : 0.930000 | Test: Loss 2.144484 Accuracy : 0.650000\n",
            "\n",
            "| Epoch: 113/1000 | Train: Loss 0.248675 Accuracy : 0.930000 | Test: Loss 2.137167 Accuracy : 0.653000\n",
            "\n",
            "| Epoch: 114/1000 | Train: Loss 0.240558 Accuracy : 0.930000 | Test: Loss 2.123496 Accuracy : 0.654000\n",
            "\n",
            "| Epoch: 115/1000 | Train: Loss 0.231793 Accuracy : 0.930000 | Test: Loss 2.107638 Accuracy : 0.656000\n",
            "\n",
            "| Epoch: 116/1000 | Train: Loss 0.222939 Accuracy : 0.930000 | Test: Loss 2.089763 Accuracy : 0.656000\n",
            "\n",
            "| Epoch: 117/1000 | Train: Loss 0.215977 Accuracy : 0.930000 | Test: Loss 2.078721 Accuracy : 0.657000\n",
            "\n",
            "| Epoch: 118/1000 | Train: Loss 0.210407 Accuracy : 0.930000 | Test: Loss 2.069582 Accuracy : 0.662000\n",
            "\n",
            "| Epoch: 119/1000 | Train: Loss 0.204676 Accuracy : 0.930000 | Test: Loss 2.060534 Accuracy : 0.664000\n",
            "\n",
            "| Epoch: 120/1000 | Train: Loss 0.199433 Accuracy : 0.930000 | Test: Loss 2.050875 Accuracy : 0.664000\n",
            "\n",
            "| Epoch: 121/1000 | Train: Loss 0.196136 Accuracy : 0.930000 | Test: Loss 2.044086 Accuracy : 0.664000\n",
            "\n",
            "| Epoch: 122/1000 | Train: Loss 0.191517 Accuracy : 0.930000 | Test: Loss 2.038257 Accuracy : 0.665000\n",
            "\n",
            "| Epoch: 123/1000 | Train: Loss 0.187402 Accuracy : 0.930000 | Test: Loss 2.033767 Accuracy : 0.666000\n",
            "\n",
            "| Epoch: 124/1000 | Train: Loss 0.183418 Accuracy : 0.930000 | Test: Loss 2.030153 Accuracy : 0.668000\n",
            "\n",
            "| Epoch: 125/1000 | Train: Loss 0.179503 Accuracy : 0.930000 | Test: Loss 2.025091 Accuracy : 0.668000\n",
            "\n",
            "| Epoch: 126/1000 | Train: Loss 0.175930 Accuracy : 0.930000 | Test: Loss 2.020280 Accuracy : 0.670000\n",
            "\n",
            "| Epoch: 127/1000 | Train: Loss 0.172618 Accuracy : 0.930000 | Test: Loss 2.015589 Accuracy : 0.672000\n",
            "\n",
            "| Epoch: 128/1000 | Train: Loss 0.170597 Accuracy : 0.930000 | Test: Loss 2.008851 Accuracy : 0.672000\n",
            "\n",
            "| Epoch: 129/1000 | Train: Loss 0.166757 Accuracy : 0.930000 | Test: Loss 1.998526 Accuracy : 0.672000\n",
            "\n",
            "| Epoch: 130/1000 | Train: Loss 0.162802 Accuracy : 0.940000 | Test: Loss 1.992065 Accuracy : 0.673000\n",
            "\n",
            "| Epoch: 131/1000 | Train: Loss 0.159691 Accuracy : 0.940000 | Test: Loss 1.984799 Accuracy : 0.675000\n",
            "\n",
            "| Epoch: 132/1000 | Train: Loss 0.157121 Accuracy : 0.940000 | Test: Loss 1.979155 Accuracy : 0.677000\n",
            "\n",
            "| Epoch: 133/1000 | Train: Loss 0.154924 Accuracy : 0.940000 | Test: Loss 1.971833 Accuracy : 0.677000\n",
            "\n",
            "| Epoch: 134/1000 | Train: Loss 0.152521 Accuracy : 0.940000 | Test: Loss 1.968806 Accuracy : 0.679000\n",
            "\n",
            "| Epoch: 135/1000 | Train: Loss 0.149891 Accuracy : 0.940000 | Test: Loss 1.957973 Accuracy : 0.679000\n",
            "\n",
            "| Epoch: 136/1000 | Train: Loss 0.146345 Accuracy : 0.950000 | Test: Loss 1.946972 Accuracy : 0.681000\n",
            "\n",
            "| Epoch: 137/1000 | Train: Loss 0.143760 Accuracy : 0.960000 | Test: Loss 1.935548 Accuracy : 0.681000\n",
            "\n",
            "| Epoch: 138/1000 | Train: Loss 0.140095 Accuracy : 0.960000 | Test: Loss 1.928953 Accuracy : 0.682000\n",
            "\n",
            "| Epoch: 139/1000 | Train: Loss 0.137248 Accuracy : 0.960000 | Test: Loss 1.921633 Accuracy : 0.684000\n",
            "\n",
            "| Epoch: 140/1000 | Train: Loss 0.134210 Accuracy : 0.960000 | Test: Loss 1.917441 Accuracy : 0.686000\n",
            "\n",
            "| Epoch: 141/1000 | Train: Loss 0.131958 Accuracy : 0.970000 | Test: Loss 1.910259 Accuracy : 0.683000\n",
            "\n",
            "| Epoch: 142/1000 | Train: Loss 0.129218 Accuracy : 0.970000 | Test: Loss 1.905667 Accuracy : 0.683000\n",
            "\n",
            "| Epoch: 143/1000 | Train: Loss 0.127073 Accuracy : 0.970000 | Test: Loss 1.902663 Accuracy : 0.685000\n",
            "\n",
            "| Epoch: 144/1000 | Train: Loss 0.124126 Accuracy : 0.970000 | Test: Loss 1.897733 Accuracy : 0.684000\n",
            "\n",
            "| Epoch: 145/1000 | Train: Loss 0.121308 Accuracy : 0.970000 | Test: Loss 1.889734 Accuracy : 0.686000\n",
            "\n",
            "| Epoch: 146/1000 | Train: Loss 0.119265 Accuracy : 0.970000 | Test: Loss 1.882454 Accuracy : 0.688000\n",
            "\n",
            "| Epoch: 147/1000 | Train: Loss 0.117890 Accuracy : 0.970000 | Test: Loss 1.879647 Accuracy : 0.688000\n",
            "\n",
            "| Epoch: 148/1000 | Train: Loss 0.116979 Accuracy : 0.970000 | Test: Loss 1.878144 Accuracy : 0.687000\n",
            "\n",
            "| Epoch: 149/1000 | Train: Loss 0.116121 Accuracy : 0.970000 | Test: Loss 1.878462 Accuracy : 0.685000\n",
            "\n",
            "| Epoch: 150/1000 | Train: Loss 0.115827 Accuracy : 0.970000 | Test: Loss 1.878237 Accuracy : 0.684000\n",
            "\n",
            "| Epoch: 151/1000 | Train: Loss 0.114211 Accuracy : 0.970000 | Test: Loss 1.874953 Accuracy : 0.686000\n",
            "\n",
            "| Epoch: 152/1000 | Train: Loss 0.113303 Accuracy : 0.970000 | Test: Loss 1.871131 Accuracy : 0.690000\n",
            "\n",
            "| Epoch: 153/1000 | Train: Loss 0.112310 Accuracy : 0.970000 | Test: Loss 1.867189 Accuracy : 0.690000\n",
            "\n",
            "| Epoch: 154/1000 | Train: Loss 0.110263 Accuracy : 0.970000 | Test: Loss 1.862150 Accuracy : 0.689000\n",
            "\n",
            "| Epoch: 155/1000 | Train: Loss 0.108508 Accuracy : 0.970000 | Test: Loss 1.858345 Accuracy : 0.690000\n",
            "\n",
            "| Epoch: 156/1000 | Train: Loss 0.107386 Accuracy : 0.970000 | Test: Loss 1.848736 Accuracy : 0.690000\n",
            "\n",
            "| Epoch: 157/1000 | Train: Loss 0.106248 Accuracy : 0.970000 | Test: Loss 1.842211 Accuracy : 0.691000\n",
            "\n",
            "| Epoch: 158/1000 | Train: Loss 0.105205 Accuracy : 0.970000 | Test: Loss 1.835913 Accuracy : 0.691000\n",
            "\n",
            "| Epoch: 159/1000 | Train: Loss 0.103186 Accuracy : 0.970000 | Test: Loss 1.831679 Accuracy : 0.692000\n",
            "\n",
            "| Epoch: 160/1000 | Train: Loss 0.101085 Accuracy : 0.970000 | Test: Loss 1.828818 Accuracy : 0.694000\n",
            "\n",
            "| Epoch: 161/1000 | Train: Loss 0.099936 Accuracy : 0.970000 | Test: Loss 1.820935 Accuracy : 0.695000\n",
            "\n",
            "| Epoch: 162/1000 | Train: Loss 0.098644 Accuracy : 0.970000 | Test: Loss 1.816163 Accuracy : 0.695000\n",
            "\n",
            "| Epoch: 163/1000 | Train: Loss 0.096059 Accuracy : 0.970000 | Test: Loss 1.807974 Accuracy : 0.696000\n",
            "\n",
            "| Epoch: 164/1000 | Train: Loss 0.093972 Accuracy : 0.970000 | Test: Loss 1.798422 Accuracy : 0.696000\n",
            "\n",
            "| Epoch: 165/1000 | Train: Loss 0.091973 Accuracy : 0.970000 | Test: Loss 1.794819 Accuracy : 0.699000\n",
            "\n",
            "| Epoch: 166/1000 | Train: Loss 0.090443 Accuracy : 0.970000 | Test: Loss 1.793069 Accuracy : 0.700000\n",
            "\n",
            "| Epoch: 167/1000 | Train: Loss 0.088969 Accuracy : 0.970000 | Test: Loss 1.790729 Accuracy : 0.701000\n",
            "\n",
            "| Epoch: 168/1000 | Train: Loss 0.088135 Accuracy : 0.970000 | Test: Loss 1.789472 Accuracy : 0.701000\n",
            "\n",
            "| Epoch: 169/1000 | Train: Loss 0.087216 Accuracy : 0.970000 | Test: Loss 1.789866 Accuracy : 0.700000\n",
            "\n",
            "| Epoch: 170/1000 | Train: Loss 0.085992 Accuracy : 0.970000 | Test: Loss 1.789194 Accuracy : 0.700000\n",
            "\n",
            "| Epoch: 171/1000 | Train: Loss 0.084232 Accuracy : 0.980000 | Test: Loss 1.785049 Accuracy : 0.699000\n",
            "\n",
            "| Epoch: 172/1000 | Train: Loss 0.083295 Accuracy : 0.980000 | Test: Loss 1.785633 Accuracy : 0.699000\n",
            "\n",
            "| Epoch: 173/1000 | Train: Loss 0.081690 Accuracy : 0.990000 | Test: Loss 1.782470 Accuracy : 0.700000\n",
            "\n",
            "| Epoch: 174/1000 | Train: Loss 0.079925 Accuracy : 0.990000 | Test: Loss 1.779470 Accuracy : 0.700000\n",
            "\n",
            "| Epoch: 175/1000 | Train: Loss 0.078823 Accuracy : 0.990000 | Test: Loss 1.778718 Accuracy : 0.702000\n",
            "\n",
            "| Epoch: 176/1000 | Train: Loss 0.077333 Accuracy : 0.990000 | Test: Loss 1.775646 Accuracy : 0.703000\n",
            "\n",
            "| Epoch: 177/1000 | Train: Loss 0.076021 Accuracy : 0.990000 | Test: Loss 1.773682 Accuracy : 0.703000\n",
            "\n",
            "| Epoch: 178/1000 | Train: Loss 0.074601 Accuracy : 0.990000 | Test: Loss 1.770164 Accuracy : 0.703000\n",
            "\n",
            "| Epoch: 179/1000 | Train: Loss 0.073371 Accuracy : 0.990000 | Test: Loss 1.762910 Accuracy : 0.703000\n",
            "\n",
            "| Epoch: 180/1000 | Train: Loss 0.071986 Accuracy : 0.990000 | Test: Loss 1.756276 Accuracy : 0.704000\n",
            "\n",
            "| Epoch: 181/1000 | Train: Loss 0.071085 Accuracy : 0.990000 | Test: Loss 1.750218 Accuracy : 0.706000\n",
            "\n",
            "| Epoch: 182/1000 | Train: Loss 0.069701 Accuracy : 0.990000 | Test: Loss 1.744282 Accuracy : 0.707000\n",
            "\n",
            "| Epoch: 183/1000 | Train: Loss 0.069410 Accuracy : 0.990000 | Test: Loss 1.740541 Accuracy : 0.707000\n",
            "\n",
            "| Epoch: 184/1000 | Train: Loss 0.069376 Accuracy : 0.990000 | Test: Loss 1.737919 Accuracy : 0.708000\n",
            "\n",
            "| Epoch: 185/1000 | Train: Loss 0.068597 Accuracy : 0.990000 | Test: Loss 1.736779 Accuracy : 0.708000\n",
            "\n",
            "| Epoch: 186/1000 | Train: Loss 0.067428 Accuracy : 0.990000 | Test: Loss 1.732471 Accuracy : 0.708000\n",
            "\n",
            "| Epoch: 187/1000 | Train: Loss 0.066272 Accuracy : 0.990000 | Test: Loss 1.728805 Accuracy : 0.713000\n",
            "\n",
            "| Epoch: 188/1000 | Train: Loss 0.065258 Accuracy : 0.990000 | Test: Loss 1.726823 Accuracy : 0.713000\n",
            "\n",
            "| Epoch: 189/1000 | Train: Loss 0.064291 Accuracy : 0.990000 | Test: Loss 1.725316 Accuracy : 0.712000\n",
            "\n",
            "| Epoch: 190/1000 | Train: Loss 0.062744 Accuracy : 0.990000 | Test: Loss 1.723866 Accuracy : 0.715000\n",
            "\n",
            "| Epoch: 191/1000 | Train: Loss 0.061658 Accuracy : 0.990000 | Test: Loss 1.720585 Accuracy : 0.715000\n",
            "\n",
            "| Epoch: 192/1000 | Train: Loss 0.060045 Accuracy : 0.990000 | Test: Loss 1.716631 Accuracy : 0.716000\n",
            "\n",
            "| Epoch: 193/1000 | Train: Loss 0.058345 Accuracy : 0.990000 | Test: Loss 1.713873 Accuracy : 0.717000\n",
            "\n",
            "| Epoch: 194/1000 | Train: Loss 0.057490 Accuracy : 0.990000 | Test: Loss 1.713725 Accuracy : 0.718000\n",
            "\n",
            "| Epoch: 195/1000 | Train: Loss 0.056937 Accuracy : 0.990000 | Test: Loss 1.714178 Accuracy : 0.717000\n",
            "\n",
            "| Epoch: 196/1000 | Train: Loss 0.056734 Accuracy : 0.990000 | Test: Loss 1.716143 Accuracy : 0.716000\n",
            "\n",
            "| Epoch: 197/1000 | Train: Loss 0.056666 Accuracy : 0.990000 | Test: Loss 1.719313 Accuracy : 0.716000\n",
            "\n",
            "| Epoch: 198/1000 | Train: Loss 0.056809 Accuracy : 0.990000 | Test: Loss 1.722360 Accuracy : 0.715000\n",
            "\n",
            "| Epoch: 199/1000 | Train: Loss 0.056181 Accuracy : 0.990000 | Test: Loss 1.724352 Accuracy : 0.718000\n",
            "\n",
            "| Epoch: 200/1000 | Train: Loss 0.055248 Accuracy : 0.990000 | Test: Loss 1.726943 Accuracy : 0.719000\n",
            "\n",
            "| Epoch: 201/1000 | Train: Loss 0.054309 Accuracy : 0.990000 | Test: Loss 1.727702 Accuracy : 0.718000\n",
            "\n",
            "| Epoch: 202/1000 | Train: Loss 0.054255 Accuracy : 0.990000 | Test: Loss 1.728938 Accuracy : 0.718000\n",
            "\n",
            "| Epoch: 203/1000 | Train: Loss 0.054242 Accuracy : 0.990000 | Test: Loss 1.729432 Accuracy : 0.718000\n",
            "\n",
            "| Epoch: 204/1000 | Train: Loss 0.054823 Accuracy : 0.990000 | Test: Loss 1.731748 Accuracy : 0.715000\n",
            "\n",
            "| Epoch: 205/1000 | Train: Loss 0.054796 Accuracy : 0.990000 | Test: Loss 1.733064 Accuracy : 0.715000\n",
            "\n",
            "| Epoch: 206/1000 | Train: Loss 0.054944 Accuracy : 0.990000 | Test: Loss 1.733958 Accuracy : 0.717000\n",
            "\n",
            "| Epoch: 207/1000 | Train: Loss 0.054614 Accuracy : 0.990000 | Test: Loss 1.730922 Accuracy : 0.718000\n",
            "\n",
            "| Epoch: 208/1000 | Train: Loss 0.054253 Accuracy : 0.990000 | Test: Loss 1.728758 Accuracy : 0.717000\n",
            "\n",
            "| Epoch: 209/1000 | Train: Loss 0.054231 Accuracy : 0.990000 | Test: Loss 1.728723 Accuracy : 0.718000\n",
            "\n",
            "| Epoch: 210/1000 | Train: Loss 0.054047 Accuracy : 0.990000 | Test: Loss 1.725748 Accuracy : 0.717000\n",
            "\n",
            "| Epoch: 211/1000 | Train: Loss 0.053278 Accuracy : 0.990000 | Test: Loss 1.720178 Accuracy : 0.719000\n",
            "\n",
            "| Epoch: 212/1000 | Train: Loss 0.052611 Accuracy : 0.990000 | Test: Loss 1.713851 Accuracy : 0.718000\n",
            "\n",
            "| Epoch: 213/1000 | Train: Loss 0.052497 Accuracy : 0.990000 | Test: Loss 1.712053 Accuracy : 0.717000\n",
            "\n",
            "| Epoch: 214/1000 | Train: Loss 0.052102 Accuracy : 0.990000 | Test: Loss 1.708609 Accuracy : 0.717000\n",
            "\n",
            "| Epoch: 215/1000 | Train: Loss 0.051776 Accuracy : 0.990000 | Test: Loss 1.707203 Accuracy : 0.717000\n",
            "\n",
            "| Epoch: 216/1000 | Train: Loss 0.051472 Accuracy : 0.990000 | Test: Loss 1.705149 Accuracy : 0.717000\n",
            "\n",
            "| Epoch: 217/1000 | Train: Loss 0.051525 Accuracy : 0.990000 | Test: Loss 1.703115 Accuracy : 0.718000\n",
            "\n",
            "| Epoch: 218/1000 | Train: Loss 0.051479 Accuracy : 0.990000 | Test: Loss 1.701734 Accuracy : 0.718000\n",
            "\n",
            "| Epoch: 219/1000 | Train: Loss 0.051551 Accuracy : 0.990000 | Test: Loss 1.698468 Accuracy : 0.719000\n",
            "\n",
            "| Epoch: 220/1000 | Train: Loss 0.051865 Accuracy : 0.990000 | Test: Loss 1.698288 Accuracy : 0.719000\n",
            "\n",
            "| Epoch: 221/1000 | Train: Loss 0.051792 Accuracy : 0.990000 | Test: Loss 1.693057 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 222/1000 | Train: Loss 0.051646 Accuracy : 0.990000 | Test: Loss 1.688316 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 223/1000 | Train: Loss 0.051197 Accuracy : 0.990000 | Test: Loss 1.683781 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 224/1000 | Train: Loss 0.050206 Accuracy : 0.990000 | Test: Loss 1.677783 Accuracy : 0.720000\n",
            "\n",
            "| Epoch: 225/1000 | Train: Loss 0.049135 Accuracy : 0.990000 | Test: Loss 1.671545 Accuracy : 0.720000\n",
            "\n",
            "| Epoch: 226/1000 | Train: Loss 0.048178 Accuracy : 0.990000 | Test: Loss 1.666820 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 227/1000 | Train: Loss 0.047309 Accuracy : 0.990000 | Test: Loss 1.666182 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 228/1000 | Train: Loss 0.046800 Accuracy : 0.990000 | Test: Loss 1.666018 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 229/1000 | Train: Loss 0.046205 Accuracy : 0.990000 | Test: Loss 1.664235 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 230/1000 | Train: Loss 0.045558 Accuracy : 0.990000 | Test: Loss 1.662719 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 231/1000 | Train: Loss 0.044932 Accuracy : 0.990000 | Test: Loss 1.661790 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 232/1000 | Train: Loss 0.043963 Accuracy : 0.990000 | Test: Loss 1.660158 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 233/1000 | Train: Loss 0.043049 Accuracy : 0.990000 | Test: Loss 1.663606 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 234/1000 | Train: Loss 0.042323 Accuracy : 0.990000 | Test: Loss 1.663169 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 235/1000 | Train: Loss 0.041423 Accuracy : 0.990000 | Test: Loss 1.661318 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 236/1000 | Train: Loss 0.040505 Accuracy : 0.990000 | Test: Loss 1.658170 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 237/1000 | Train: Loss 0.040085 Accuracy : 0.990000 | Test: Loss 1.654907 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 238/1000 | Train: Loss 0.039355 Accuracy : 0.990000 | Test: Loss 1.649742 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 239/1000 | Train: Loss 0.038928 Accuracy : 0.990000 | Test: Loss 1.647017 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 240/1000 | Train: Loss 0.038655 Accuracy : 0.990000 | Test: Loss 1.643721 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 241/1000 | Train: Loss 0.038142 Accuracy : 0.990000 | Test: Loss 1.640802 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 242/1000 | Train: Loss 0.037760 Accuracy : 0.990000 | Test: Loss 1.639464 Accuracy : 0.721000\n",
            "\n",
            "| Epoch: 243/1000 | Train: Loss 0.037612 Accuracy : 0.990000 | Test: Loss 1.638237 Accuracy : 0.720000\n",
            "\n",
            "| Epoch: 244/1000 | Train: Loss 0.037331 Accuracy : 0.990000 | Test: Loss 1.634061 Accuracy : 0.719000\n",
            "\n",
            "| Epoch: 245/1000 | Train: Loss 0.037247 Accuracy : 0.990000 | Test: Loss 1.631938 Accuracy : 0.719000\n",
            "\n",
            "| Epoch: 246/1000 | Train: Loss 0.037214 Accuracy : 0.990000 | Test: Loss 1.631031 Accuracy : 0.719000\n",
            "\n",
            "| Epoch: 247/1000 | Train: Loss 0.037493 Accuracy : 0.990000 | Test: Loss 1.630695 Accuracy : 0.720000\n",
            "\n",
            "| Epoch: 248/1000 | Train: Loss 0.037604 Accuracy : 0.990000 | Test: Loss 1.629941 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 249/1000 | Train: Loss 0.037477 Accuracy : 0.990000 | Test: Loss 1.630049 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 250/1000 | Train: Loss 0.037437 Accuracy : 0.990000 | Test: Loss 1.627695 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 251/1000 | Train: Loss 0.037456 Accuracy : 0.990000 | Test: Loss 1.624431 Accuracy : 0.723000\n",
            "\n",
            "| Epoch: 252/1000 | Train: Loss 0.037243 Accuracy : 0.990000 | Test: Loss 1.621663 Accuracy : 0.722000\n",
            "\n",
            "| Epoch: 253/1000 | Train: Loss 0.036572 Accuracy : 0.990000 | Test: Loss 1.619972 Accuracy : 0.724000\n",
            "\n",
            "| Epoch: 254/1000 | Train: Loss 0.036025 Accuracy : 0.990000 | Test: Loss 1.616600 Accuracy : 0.724000\n",
            "\n",
            "| Epoch: 255/1000 | Train: Loss 0.035006 Accuracy : 0.990000 | Test: Loss 1.613187 Accuracy : 0.726000\n",
            "\n",
            "| Epoch: 256/1000 | Train: Loss 0.034233 Accuracy : 0.990000 | Test: Loss 1.610961 Accuracy : 0.726000\n",
            "\n",
            "| Epoch: 257/1000 | Train: Loss 0.033349 Accuracy : 0.990000 | Test: Loss 1.607558 Accuracy : 0.727000\n",
            "\n",
            "| Epoch: 258/1000 | Train: Loss 0.032512 Accuracy : 0.990000 | Test: Loss 1.603000 Accuracy : 0.727000\n",
            "\n",
            "| Epoch: 259/1000 | Train: Loss 0.031730 Accuracy : 0.990000 | Test: Loss 1.599526 Accuracy : 0.727000\n",
            "\n",
            "| Epoch: 260/1000 | Train: Loss 0.031465 Accuracy : 0.990000 | Test: Loss 1.598694 Accuracy : 0.726000\n",
            "\n",
            "| Epoch: 261/1000 | Train: Loss 0.031384 Accuracy : 0.990000 | Test: Loss 1.596383 Accuracy : 0.728000\n",
            "\n",
            "| Epoch: 262/1000 | Train: Loss 0.030746 Accuracy : 0.990000 | Test: Loss 1.594254 Accuracy : 0.728000\n",
            "\n",
            "| Epoch: 263/1000 | Train: Loss 0.030290 Accuracy : 0.990000 | Test: Loss 1.593856 Accuracy : 0.728000\n",
            "\n",
            "| Epoch: 264/1000 | Train: Loss 0.029945 Accuracy : 0.990000 | Test: Loss 1.593511 Accuracy : 0.729000\n",
            "\n",
            "| Epoch: 265/1000 | Train: Loss 0.029602 Accuracy : 0.990000 | Test: Loss 1.592355 Accuracy : 0.730000\n",
            "\n",
            "| Epoch: 266/1000 | Train: Loss 0.029475 Accuracy : 0.990000 | Test: Loss 1.592364 Accuracy : 0.730000\n",
            "\n",
            "| Epoch: 267/1000 | Train: Loss 0.028755 Accuracy : 0.990000 | Test: Loss 1.593588 Accuracy : 0.732000\n",
            "\n",
            "| Epoch: 268/1000 | Train: Loss 0.027934 Accuracy : 0.990000 | Test: Loss 1.593043 Accuracy : 0.733000\n",
            "\n",
            "| Epoch: 269/1000 | Train: Loss 0.027358 Accuracy : 0.990000 | Test: Loss 1.591045 Accuracy : 0.734000\n",
            "\n",
            "| Epoch: 270/1000 | Train: Loss 0.026966 Accuracy : 0.990000 | Test: Loss 1.592582 Accuracy : 0.733000\n",
            "\n",
            "| Epoch: 271/1000 | Train: Loss 0.026853 Accuracy : 0.990000 | Test: Loss 1.593802 Accuracy : 0.733000\n",
            "\n",
            "| Epoch: 272/1000 | Train: Loss 0.026457 Accuracy : 0.990000 | Test: Loss 1.595099 Accuracy : 0.733000\n",
            "\n",
            "| Epoch: 273/1000 | Train: Loss 0.026469 Accuracy : 0.990000 | Test: Loss 1.594879 Accuracy : 0.732000\n",
            "\n",
            "| Epoch: 274/1000 | Train: Loss 0.026677 Accuracy : 0.990000 | Test: Loss 1.593886 Accuracy : 0.733000\n",
            "\n",
            "| Epoch: 275/1000 | Train: Loss 0.026635 Accuracy : 0.990000 | Test: Loss 1.594871 Accuracy : 0.732000\n",
            "\n",
            "| Epoch: 276/1000 | Train: Loss 0.026648 Accuracy : 0.990000 | Test: Loss 1.594656 Accuracy : 0.732000\n",
            "\n",
            "| Epoch: 277/1000 | Train: Loss 0.026580 Accuracy : 0.990000 | Test: Loss 1.596437 Accuracy : 0.732000\n",
            "\n",
            "| Epoch: 278/1000 | Train: Loss 0.026561 Accuracy : 0.990000 | Test: Loss 1.595194 Accuracy : 0.732000\n",
            "\n",
            "| Epoch: 279/1000 | Train: Loss 0.026513 Accuracy : 0.990000 | Test: Loss 1.595291 Accuracy : 0.733000\n",
            "\n",
            "| Epoch: 280/1000 | Train: Loss 0.026532 Accuracy : 0.990000 | Test: Loss 1.596754 Accuracy : 0.734000\n",
            "\n",
            "| Epoch: 281/1000 | Train: Loss 0.026515 Accuracy : 0.990000 | Test: Loss 1.597112 Accuracy : 0.734000\n",
            "\n",
            "| Epoch: 282/1000 | Train: Loss 0.026308 Accuracy : 0.990000 | Test: Loss 1.597258 Accuracy : 0.734000\n",
            "\n",
            "| Epoch: 283/1000 | Train: Loss 0.026475 Accuracy : 0.990000 | Test: Loss 1.597575 Accuracy : 0.735000\n",
            "\n",
            "| Epoch: 284/1000 | Train: Loss 0.026141 Accuracy : 0.990000 | Test: Loss 1.596205 Accuracy : 0.736000\n",
            "\n",
            "| Epoch: 285/1000 | Train: Loss 0.025614 Accuracy : 0.990000 | Test: Loss 1.595422 Accuracy : 0.735000\n",
            "\n",
            "| Epoch: 286/1000 | Train: Loss 0.025454 Accuracy : 0.990000 | Test: Loss 1.593733 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 287/1000 | Train: Loss 0.024847 Accuracy : 0.990000 | Test: Loss 1.593212 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 288/1000 | Train: Loss 0.024249 Accuracy : 0.990000 | Test: Loss 1.591131 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 289/1000 | Train: Loss 0.023451 Accuracy : 0.990000 | Test: Loss 1.590066 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 290/1000 | Train: Loss 0.022145 Accuracy : 0.990000 | Test: Loss 1.587964 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 291/1000 | Train: Loss 0.020778 Accuracy : 0.990000 | Test: Loss 1.585778 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 292/1000 | Train: Loss 0.020030 Accuracy : 0.990000 | Test: Loss 1.583519 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 293/1000 | Train: Loss 0.019738 Accuracy : 0.990000 | Test: Loss 1.582065 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 294/1000 | Train: Loss 0.019182 Accuracy : 0.990000 | Test: Loss 1.579126 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 295/1000 | Train: Loss 0.018646 Accuracy : 0.990000 | Test: Loss 1.578694 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 296/1000 | Train: Loss 0.018286 Accuracy : 0.990000 | Test: Loss 1.576721 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 297/1000 | Train: Loss 0.017568 Accuracy : 0.990000 | Test: Loss 1.573786 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 298/1000 | Train: Loss 0.017229 Accuracy : 0.990000 | Test: Loss 1.572831 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 299/1000 | Train: Loss 0.016833 Accuracy : 0.990000 | Test: Loss 1.570789 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 300/1000 | Train: Loss 0.016653 Accuracy : 0.990000 | Test: Loss 1.570901 Accuracy : 0.739000\n",
            "\n",
            "| Epoch: 301/1000 | Train: Loss 0.016435 Accuracy : 0.990000 | Test: Loss 1.567687 Accuracy : 0.739000\n",
            "\n",
            "| Epoch: 302/1000 | Train: Loss 0.016081 Accuracy : 0.990000 | Test: Loss 1.565577 Accuracy : 0.739000\n",
            "\n",
            "| Epoch: 303/1000 | Train: Loss 0.015720 Accuracy : 0.990000 | Test: Loss 1.563267 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 304/1000 | Train: Loss 0.015475 Accuracy : 0.990000 | Test: Loss 1.562296 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 305/1000 | Train: Loss 0.015243 Accuracy : 0.990000 | Test: Loss 1.559568 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 306/1000 | Train: Loss 0.015019 Accuracy : 0.990000 | Test: Loss 1.557225 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 307/1000 | Train: Loss 0.014942 Accuracy : 0.990000 | Test: Loss 1.554916 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 308/1000 | Train: Loss 0.014505 Accuracy : 0.990000 | Test: Loss 1.551594 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 309/1000 | Train: Loss 0.014543 Accuracy : 0.990000 | Test: Loss 1.553372 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 310/1000 | Train: Loss 0.014351 Accuracy : 0.990000 | Test: Loss 1.553898 Accuracy : 0.736000\n",
            "\n",
            "| Epoch: 311/1000 | Train: Loss 0.014424 Accuracy : 0.990000 | Test: Loss 1.552519 Accuracy : 0.736000\n",
            "\n",
            "| Epoch: 312/1000 | Train: Loss 0.014305 Accuracy : 0.990000 | Test: Loss 1.550308 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 313/1000 | Train: Loss 0.014073 Accuracy : 0.990000 | Test: Loss 1.548015 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 314/1000 | Train: Loss 0.014071 Accuracy : 0.990000 | Test: Loss 1.546191 Accuracy : 0.736000\n",
            "\n",
            "| Epoch: 315/1000 | Train: Loss 0.013916 Accuracy : 0.990000 | Test: Loss 1.543560 Accuracy : 0.737000\n",
            "\n",
            "| Epoch: 316/1000 | Train: Loss 0.013511 Accuracy : 0.990000 | Test: Loss 1.540262 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 317/1000 | Train: Loss 0.013297 Accuracy : 0.990000 | Test: Loss 1.540366 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 318/1000 | Train: Loss 0.012967 Accuracy : 0.990000 | Test: Loss 1.538576 Accuracy : 0.738000\n",
            "\n",
            "| Epoch: 319/1000 | Train: Loss 0.012768 Accuracy : 0.990000 | Test: Loss 1.538718 Accuracy : 0.739000\n",
            "\n",
            "| Epoch: 320/1000 | Train: Loss 0.012723 Accuracy : 0.990000 | Test: Loss 1.538346 Accuracy : 0.739000\n",
            "\n",
            "| Epoch: 321/1000 | Train: Loss 0.012625 Accuracy : 0.990000 | Test: Loss 1.538754 Accuracy : 0.739000\n",
            "\n",
            "| Epoch: 322/1000 | Train: Loss 0.012785 Accuracy : 0.990000 | Test: Loss 1.539435 Accuracy : 0.740000\n",
            "\n",
            "| Epoch: 323/1000 | Train: Loss 0.012710 Accuracy : 0.990000 | Test: Loss 1.540006 Accuracy : 0.741000\n",
            "\n",
            "| Epoch: 324/1000 | Train: Loss 0.012849 Accuracy : 0.990000 | Test: Loss 1.540126 Accuracy : 0.741000\n",
            "\n",
            "| Epoch: 325/1000 | Train: Loss 0.012681 Accuracy : 0.990000 | Test: Loss 1.539701 Accuracy : 0.742000\n",
            "\n",
            "| Epoch: 326/1000 | Train: Loss 0.012291 Accuracy : 0.990000 | Test: Loss 1.538905 Accuracy : 0.741000\n",
            "\n",
            "| Epoch: 327/1000 | Train: Loss 0.012100 Accuracy : 0.990000 | Test: Loss 1.539661 Accuracy : 0.741000\n",
            "\n",
            "| Epoch: 328/1000 | Train: Loss 0.012185 Accuracy : 0.990000 | Test: Loss 1.542316 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 329/1000 | Train: Loss 0.012002 Accuracy : 0.990000 | Test: Loss 1.545713 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 330/1000 | Train: Loss 0.011780 Accuracy : 0.990000 | Test: Loss 1.545632 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 331/1000 | Train: Loss 0.011284 Accuracy : 0.990000 | Test: Loss 1.546314 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 332/1000 | Train: Loss 0.011029 Accuracy : 0.990000 | Test: Loss 1.544982 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 333/1000 | Train: Loss 0.010776 Accuracy : 0.990000 | Test: Loss 1.545177 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 334/1000 | Train: Loss 0.010534 Accuracy : 0.990000 | Test: Loss 1.545721 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 335/1000 | Train: Loss 0.010343 Accuracy : 0.990000 | Test: Loss 1.544639 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 336/1000 | Train: Loss 0.010366 Accuracy : 0.990000 | Test: Loss 1.545620 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 337/1000 | Train: Loss 0.010331 Accuracy : 0.990000 | Test: Loss 1.547348 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 338/1000 | Train: Loss 0.009924 Accuracy : 0.990000 | Test: Loss 1.547544 Accuracy : 0.743000\n",
            "\n",
            "| Epoch: 339/1000 | Train: Loss 0.009718 Accuracy : 0.990000 | Test: Loss 1.550451 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 340/1000 | Train: Loss 0.009479 Accuracy : 0.990000 | Test: Loss 1.549984 Accuracy : 0.741000\n",
            "\n",
            "| Epoch: 341/1000 | Train: Loss 0.009662 Accuracy : 0.990000 | Test: Loss 1.549953 Accuracy : 0.740000\n",
            "\n",
            "| Epoch: 342/1000 | Train: Loss 0.009908 Accuracy : 0.990000 | Test: Loss 1.548797 Accuracy : 0.739000\n",
            "\n",
            "| Epoch: 343/1000 | Train: Loss 0.010250 Accuracy : 0.990000 | Test: Loss 1.546815 Accuracy : 0.739000\n",
            "\n",
            "| Epoch: 344/1000 | Train: Loss 0.010593 Accuracy : 0.990000 | Test: Loss 1.544178 Accuracy : 0.740000\n",
            "\n",
            "| Epoch: 345/1000 | Train: Loss 0.010679 Accuracy : 0.990000 | Test: Loss 1.542775 Accuracy : 0.741000\n",
            "\n",
            "| Epoch: 346/1000 | Train: Loss 0.010472 Accuracy : 0.990000 | Test: Loss 1.543690 Accuracy : 0.741000\n",
            "\n",
            "| Epoch: 347/1000 | Train: Loss 0.010268 Accuracy : 0.990000 | Test: Loss 1.542662 Accuracy : 0.742000\n",
            "\n",
            "| Epoch: 348/1000 | Train: Loss 0.010072 Accuracy : 0.990000 | Test: Loss 1.544750 Accuracy : 0.742000\n",
            "\n",
            "| Epoch: 349/1000 | Train: Loss 0.009927 Accuracy : 0.990000 | Test: Loss 1.547350 Accuracy : 0.743000\n",
            "\n",
            "| Epoch: 350/1000 | Train: Loss 0.009567 Accuracy : 0.990000 | Test: Loss 1.548719 Accuracy : 0.742000\n",
            "\n",
            "| Epoch: 351/1000 | Train: Loss 0.009254 Accuracy : 0.990000 | Test: Loss 1.549109 Accuracy : 0.743000\n",
            "\n",
            "| Epoch: 352/1000 | Train: Loss 0.008670 Accuracy : 0.990000 | Test: Loss 1.547966 Accuracy : 0.745000\n",
            "\n",
            "| Epoch: 353/1000 | Train: Loss 0.008363 Accuracy : 0.990000 | Test: Loss 1.548035 Accuracy : 0.745000\n",
            "\n",
            "| Epoch: 354/1000 | Train: Loss 0.008182 Accuracy : 0.990000 | Test: Loss 1.550096 Accuracy : 0.745000\n",
            "\n",
            "| Epoch: 355/1000 | Train: Loss 0.008131 Accuracy : 0.990000 | Test: Loss 1.550585 Accuracy : 0.745000\n",
            "\n",
            "| Epoch: 356/1000 | Train: Loss 0.008022 Accuracy : 0.990000 | Test: Loss 1.550511 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 357/1000 | Train: Loss 0.008126 Accuracy : 0.990000 | Test: Loss 1.550719 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 358/1000 | Train: Loss 0.008264 Accuracy : 0.990000 | Test: Loss 1.549665 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 359/1000 | Train: Loss 0.008297 Accuracy : 0.990000 | Test: Loss 1.548129 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 360/1000 | Train: Loss 0.008510 Accuracy : 0.990000 | Test: Loss 1.545690 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 361/1000 | Train: Loss 0.008556 Accuracy : 0.990000 | Test: Loss 1.545544 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 362/1000 | Train: Loss 0.008578 Accuracy : 0.990000 | Test: Loss 1.543973 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 363/1000 | Train: Loss 0.008216 Accuracy : 0.990000 | Test: Loss 1.543406 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 364/1000 | Train: Loss 0.007902 Accuracy : 0.990000 | Test: Loss 1.542942 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 365/1000 | Train: Loss 0.007836 Accuracy : 0.990000 | Test: Loss 1.543270 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 366/1000 | Train: Loss 0.007674 Accuracy : 0.990000 | Test: Loss 1.539559 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 367/1000 | Train: Loss 0.007590 Accuracy : 0.990000 | Test: Loss 1.539428 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 368/1000 | Train: Loss 0.007555 Accuracy : 0.990000 | Test: Loss 1.538477 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 369/1000 | Train: Loss 0.007733 Accuracy : 0.990000 | Test: Loss 1.539976 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 370/1000 | Train: Loss 0.007974 Accuracy : 0.990000 | Test: Loss 1.540766 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 371/1000 | Train: Loss 0.008053 Accuracy : 0.990000 | Test: Loss 1.540387 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 372/1000 | Train: Loss 0.008014 Accuracy : 0.990000 | Test: Loss 1.541414 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 373/1000 | Train: Loss 0.008138 Accuracy : 0.990000 | Test: Loss 1.542051 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 374/1000 | Train: Loss 0.008215 Accuracy : 0.990000 | Test: Loss 1.546696 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 375/1000 | Train: Loss 0.008027 Accuracy : 0.990000 | Test: Loss 1.548703 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 376/1000 | Train: Loss 0.007807 Accuracy : 0.990000 | Test: Loss 1.550161 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 377/1000 | Train: Loss 0.007599 Accuracy : 0.990000 | Test: Loss 1.550273 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 378/1000 | Train: Loss 0.007362 Accuracy : 1.000000 | Test: Loss 1.548564 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 379/1000 | Train: Loss 0.007036 Accuracy : 1.000000 | Test: Loss 1.546645 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 380/1000 | Train: Loss 0.006811 Accuracy : 1.000000 | Test: Loss 1.545082 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 381/1000 | Train: Loss 0.006531 Accuracy : 1.000000 | Test: Loss 1.546045 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 382/1000 | Train: Loss 0.006194 Accuracy : 1.000000 | Test: Loss 1.544891 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 383/1000 | Train: Loss 0.006077 Accuracy : 1.000000 | Test: Loss 1.545197 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 384/1000 | Train: Loss 0.005951 Accuracy : 1.000000 | Test: Loss 1.544254 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 385/1000 | Train: Loss 0.005671 Accuracy : 1.000000 | Test: Loss 1.544981 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 386/1000 | Train: Loss 0.005518 Accuracy : 1.000000 | Test: Loss 1.545570 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 387/1000 | Train: Loss 0.005385 Accuracy : 1.000000 | Test: Loss 1.544164 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 388/1000 | Train: Loss 0.005213 Accuracy : 1.000000 | Test: Loss 1.544392 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 389/1000 | Train: Loss 0.005037 Accuracy : 1.000000 | Test: Loss 1.543773 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 390/1000 | Train: Loss 0.004966 Accuracy : 1.000000 | Test: Loss 1.542693 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 391/1000 | Train: Loss 0.004881 Accuracy : 1.000000 | Test: Loss 1.540882 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 392/1000 | Train: Loss 0.004852 Accuracy : 1.000000 | Test: Loss 1.539555 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 393/1000 | Train: Loss 0.004751 Accuracy : 1.000000 | Test: Loss 1.538035 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 394/1000 | Train: Loss 0.004454 Accuracy : 1.000000 | Test: Loss 1.537616 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 395/1000 | Train: Loss 0.004277 Accuracy : 1.000000 | Test: Loss 1.535993 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 396/1000 | Train: Loss 0.004238 Accuracy : 1.000000 | Test: Loss 1.535943 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 397/1000 | Train: Loss 0.004141 Accuracy : 1.000000 | Test: Loss 1.538061 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 398/1000 | Train: Loss 0.003952 Accuracy : 1.000000 | Test: Loss 1.537988 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 399/1000 | Train: Loss 0.003836 Accuracy : 1.000000 | Test: Loss 1.539301 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 400/1000 | Train: Loss 0.003697 Accuracy : 1.000000 | Test: Loss 1.539970 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 401/1000 | Train: Loss 0.003605 Accuracy : 1.000000 | Test: Loss 1.540509 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 402/1000 | Train: Loss 0.003626 Accuracy : 1.000000 | Test: Loss 1.541508 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 403/1000 | Train: Loss 0.003531 Accuracy : 1.000000 | Test: Loss 1.540662 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 404/1000 | Train: Loss 0.003474 Accuracy : 1.000000 | Test: Loss 1.538118 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 405/1000 | Train: Loss 0.003476 Accuracy : 1.000000 | Test: Loss 1.539258 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 406/1000 | Train: Loss 0.003485 Accuracy : 1.000000 | Test: Loss 1.540559 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 407/1000 | Train: Loss 0.003486 Accuracy : 1.000000 | Test: Loss 1.543801 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 408/1000 | Train: Loss 0.003546 Accuracy : 1.000000 | Test: Loss 1.544572 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 409/1000 | Train: Loss 0.003538 Accuracy : 1.000000 | Test: Loss 1.546104 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 410/1000 | Train: Loss 0.003590 Accuracy : 1.000000 | Test: Loss 1.547212 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 411/1000 | Train: Loss 0.003616 Accuracy : 1.000000 | Test: Loss 1.546610 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 412/1000 | Train: Loss 0.003527 Accuracy : 1.000000 | Test: Loss 1.545703 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 413/1000 | Train: Loss 0.003496 Accuracy : 1.000000 | Test: Loss 1.544901 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 414/1000 | Train: Loss 0.003445 Accuracy : 1.000000 | Test: Loss 1.543012 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 415/1000 | Train: Loss 0.003502 Accuracy : 1.000000 | Test: Loss 1.543559 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 416/1000 | Train: Loss 0.003532 Accuracy : 1.000000 | Test: Loss 1.541417 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 417/1000 | Train: Loss 0.003490 Accuracy : 1.000000 | Test: Loss 1.538942 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 418/1000 | Train: Loss 0.003558 Accuracy : 1.000000 | Test: Loss 1.540085 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 419/1000 | Train: Loss 0.003538 Accuracy : 1.000000 | Test: Loss 1.539438 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 420/1000 | Train: Loss 0.003370 Accuracy : 1.000000 | Test: Loss 1.539980 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 421/1000 | Train: Loss 0.003179 Accuracy : 1.000000 | Test: Loss 1.539972 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 422/1000 | Train: Loss 0.003148 Accuracy : 1.000000 | Test: Loss 1.539925 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 423/1000 | Train: Loss 0.003130 Accuracy : 1.000000 | Test: Loss 1.540196 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 424/1000 | Train: Loss 0.003107 Accuracy : 1.000000 | Test: Loss 1.541202 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 425/1000 | Train: Loss 0.003108 Accuracy : 1.000000 | Test: Loss 1.541566 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 426/1000 | Train: Loss 0.003157 Accuracy : 1.000000 | Test: Loss 1.541736 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 427/1000 | Train: Loss 0.003231 Accuracy : 1.000000 | Test: Loss 1.541903 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 428/1000 | Train: Loss 0.003321 Accuracy : 1.000000 | Test: Loss 1.541106 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 429/1000 | Train: Loss 0.003427 Accuracy : 1.000000 | Test: Loss 1.541433 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 430/1000 | Train: Loss 0.003521 Accuracy : 1.000000 | Test: Loss 1.541717 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 431/1000 | Train: Loss 0.003641 Accuracy : 1.000000 | Test: Loss 1.542567 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 432/1000 | Train: Loss 0.003740 Accuracy : 1.000000 | Test: Loss 1.545399 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 433/1000 | Train: Loss 0.003745 Accuracy : 1.000000 | Test: Loss 1.547885 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 434/1000 | Train: Loss 0.003767 Accuracy : 1.000000 | Test: Loss 1.547536 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 435/1000 | Train: Loss 0.003753 Accuracy : 1.000000 | Test: Loss 1.548036 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 436/1000 | Train: Loss 0.003656 Accuracy : 1.000000 | Test: Loss 1.547794 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 437/1000 | Train: Loss 0.003650 Accuracy : 1.000000 | Test: Loss 1.547795 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 438/1000 | Train: Loss 0.003602 Accuracy : 1.000000 | Test: Loss 1.545783 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 439/1000 | Train: Loss 0.003578 Accuracy : 1.000000 | Test: Loss 1.543914 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 440/1000 | Train: Loss 0.003470 Accuracy : 1.000000 | Test: Loss 1.544018 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 441/1000 | Train: Loss 0.003293 Accuracy : 1.000000 | Test: Loss 1.543912 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 442/1000 | Train: Loss 0.003080 Accuracy : 1.000000 | Test: Loss 1.542657 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 443/1000 | Train: Loss 0.002957 Accuracy : 1.000000 | Test: Loss 1.542673 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 444/1000 | Train: Loss 0.002884 Accuracy : 1.000000 | Test: Loss 1.543372 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 445/1000 | Train: Loss 0.002898 Accuracy : 1.000000 | Test: Loss 1.544943 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 446/1000 | Train: Loss 0.002905 Accuracy : 1.000000 | Test: Loss 1.545238 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 447/1000 | Train: Loss 0.002985 Accuracy : 1.000000 | Test: Loss 1.547812 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 448/1000 | Train: Loss 0.003049 Accuracy : 1.000000 | Test: Loss 1.548765 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 449/1000 | Train: Loss 0.003028 Accuracy : 1.000000 | Test: Loss 1.549912 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 450/1000 | Train: Loss 0.003010 Accuracy : 1.000000 | Test: Loss 1.549485 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 451/1000 | Train: Loss 0.002987 Accuracy : 1.000000 | Test: Loss 1.549466 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 452/1000 | Train: Loss 0.002873 Accuracy : 1.000000 | Test: Loss 1.547607 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 453/1000 | Train: Loss 0.002823 Accuracy : 1.000000 | Test: Loss 1.546865 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 454/1000 | Train: Loss 0.002747 Accuracy : 1.000000 | Test: Loss 1.546345 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 455/1000 | Train: Loss 0.002658 Accuracy : 1.000000 | Test: Loss 1.545414 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 456/1000 | Train: Loss 0.002641 Accuracy : 1.000000 | Test: Loss 1.544580 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 457/1000 | Train: Loss 0.002642 Accuracy : 1.000000 | Test: Loss 1.543944 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 458/1000 | Train: Loss 0.002572 Accuracy : 1.000000 | Test: Loss 1.543383 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 459/1000 | Train: Loss 0.002548 Accuracy : 1.000000 | Test: Loss 1.543131 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 460/1000 | Train: Loss 0.002566 Accuracy : 1.000000 | Test: Loss 1.543803 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 461/1000 | Train: Loss 0.002588 Accuracy : 1.000000 | Test: Loss 1.543836 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 462/1000 | Train: Loss 0.002574 Accuracy : 1.000000 | Test: Loss 1.543041 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 463/1000 | Train: Loss 0.002526 Accuracy : 1.000000 | Test: Loss 1.542499 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 464/1000 | Train: Loss 0.002443 Accuracy : 1.000000 | Test: Loss 1.542401 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 465/1000 | Train: Loss 0.002347 Accuracy : 1.000000 | Test: Loss 1.541850 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 466/1000 | Train: Loss 0.002264 Accuracy : 1.000000 | Test: Loss 1.542130 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 467/1000 | Train: Loss 0.002145 Accuracy : 1.000000 | Test: Loss 1.541466 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 468/1000 | Train: Loss 0.002133 Accuracy : 1.000000 | Test: Loss 1.542326 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 469/1000 | Train: Loss 0.002101 Accuracy : 1.000000 | Test: Loss 1.544213 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 470/1000 | Train: Loss 0.002019 Accuracy : 1.000000 | Test: Loss 1.542039 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 471/1000 | Train: Loss 0.001980 Accuracy : 1.000000 | Test: Loss 1.541214 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 472/1000 | Train: Loss 0.001954 Accuracy : 1.000000 | Test: Loss 1.539287 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 473/1000 | Train: Loss 0.001977 Accuracy : 1.000000 | Test: Loss 1.539855 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 474/1000 | Train: Loss 0.001968 Accuracy : 1.000000 | Test: Loss 1.539227 Accuracy : 0.745000\n",
            "\n",
            "| Epoch: 475/1000 | Train: Loss 0.001933 Accuracy : 1.000000 | Test: Loss 1.538717 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 476/1000 | Train: Loss 0.001899 Accuracy : 1.000000 | Test: Loss 1.539101 Accuracy : 0.743000\n",
            "\n",
            "| Epoch: 477/1000 | Train: Loss 0.001856 Accuracy : 1.000000 | Test: Loss 1.540311 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 478/1000 | Train: Loss 0.001893 Accuracy : 1.000000 | Test: Loss 1.541630 Accuracy : 0.743000\n",
            "\n",
            "| Epoch: 479/1000 | Train: Loss 0.001942 Accuracy : 1.000000 | Test: Loss 1.541078 Accuracy : 0.743000\n",
            "\n",
            "| Epoch: 480/1000 | Train: Loss 0.001973 Accuracy : 1.000000 | Test: Loss 1.542138 Accuracy : 0.744000\n",
            "\n",
            "| Epoch: 481/1000 | Train: Loss 0.002016 Accuracy : 1.000000 | Test: Loss 1.539792 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 482/1000 | Train: Loss 0.002087 Accuracy : 1.000000 | Test: Loss 1.539018 Accuracy : 0.745000\n",
            "\n",
            "| Epoch: 483/1000 | Train: Loss 0.002199 Accuracy : 1.000000 | Test: Loss 1.539667 Accuracy : 0.745000\n",
            "\n",
            "| Epoch: 484/1000 | Train: Loss 0.002347 Accuracy : 1.000000 | Test: Loss 1.540119 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 485/1000 | Train: Loss 0.002434 Accuracy : 1.000000 | Test: Loss 1.539447 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 486/1000 | Train: Loss 0.002471 Accuracy : 1.000000 | Test: Loss 1.537252 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 487/1000 | Train: Loss 0.002465 Accuracy : 1.000000 | Test: Loss 1.537007 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 488/1000 | Train: Loss 0.002483 Accuracy : 1.000000 | Test: Loss 1.537096 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 489/1000 | Train: Loss 0.002434 Accuracy : 1.000000 | Test: Loss 1.535812 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 490/1000 | Train: Loss 0.002412 Accuracy : 1.000000 | Test: Loss 1.536958 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 491/1000 | Train: Loss 0.002401 Accuracy : 1.000000 | Test: Loss 1.536779 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 492/1000 | Train: Loss 0.002479 Accuracy : 1.000000 | Test: Loss 1.538380 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 493/1000 | Train: Loss 0.002545 Accuracy : 1.000000 | Test: Loss 1.540044 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 494/1000 | Train: Loss 0.002645 Accuracy : 1.000000 | Test: Loss 1.542791 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 495/1000 | Train: Loss 0.002687 Accuracy : 1.000000 | Test: Loss 1.544037 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 496/1000 | Train: Loss 0.002741 Accuracy : 1.000000 | Test: Loss 1.545543 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 497/1000 | Train: Loss 0.002745 Accuracy : 1.000000 | Test: Loss 1.545063 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 498/1000 | Train: Loss 0.002758 Accuracy : 1.000000 | Test: Loss 1.544496 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 499/1000 | Train: Loss 0.002756 Accuracy : 1.000000 | Test: Loss 1.542927 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 500/1000 | Train: Loss 0.002657 Accuracy : 1.000000 | Test: Loss 1.544122 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 501/1000 | Train: Loss 0.002599 Accuracy : 1.000000 | Test: Loss 1.545542 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 502/1000 | Train: Loss 0.002438 Accuracy : 1.000000 | Test: Loss 1.545953 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 503/1000 | Train: Loss 0.002390 Accuracy : 1.000000 | Test: Loss 1.546779 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 504/1000 | Train: Loss 0.002392 Accuracy : 1.000000 | Test: Loss 1.547428 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 505/1000 | Train: Loss 0.002427 Accuracy : 1.000000 | Test: Loss 1.550010 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 506/1000 | Train: Loss 0.002408 Accuracy : 1.000000 | Test: Loss 1.550526 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 507/1000 | Train: Loss 0.002505 Accuracy : 1.000000 | Test: Loss 1.552705 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 508/1000 | Train: Loss 0.002524 Accuracy : 1.000000 | Test: Loss 1.552724 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 509/1000 | Train: Loss 0.002550 Accuracy : 1.000000 | Test: Loss 1.553751 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 510/1000 | Train: Loss 0.002652 Accuracy : 1.000000 | Test: Loss 1.554825 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 511/1000 | Train: Loss 0.002672 Accuracy : 1.000000 | Test: Loss 1.556202 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 512/1000 | Train: Loss 0.002624 Accuracy : 1.000000 | Test: Loss 1.554529 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 513/1000 | Train: Loss 0.002526 Accuracy : 1.000000 | Test: Loss 1.553201 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 514/1000 | Train: Loss 0.002448 Accuracy : 1.000000 | Test: Loss 1.550513 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 515/1000 | Train: Loss 0.002325 Accuracy : 1.000000 | Test: Loss 1.548760 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 516/1000 | Train: Loss 0.002203 Accuracy : 1.000000 | Test: Loss 1.547953 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 517/1000 | Train: Loss 0.002136 Accuracy : 1.000000 | Test: Loss 1.546399 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 518/1000 | Train: Loss 0.002018 Accuracy : 1.000000 | Test: Loss 1.544948 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 519/1000 | Train: Loss 0.001926 Accuracy : 1.000000 | Test: Loss 1.543983 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 520/1000 | Train: Loss 0.001849 Accuracy : 1.000000 | Test: Loss 1.544368 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 521/1000 | Train: Loss 0.001813 Accuracy : 1.000000 | Test: Loss 1.542835 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 522/1000 | Train: Loss 0.001730 Accuracy : 1.000000 | Test: Loss 1.542979 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 523/1000 | Train: Loss 0.001647 Accuracy : 1.000000 | Test: Loss 1.542179 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 524/1000 | Train: Loss 0.001603 Accuracy : 1.000000 | Test: Loss 1.538751 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 525/1000 | Train: Loss 0.001574 Accuracy : 1.000000 | Test: Loss 1.535166 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 526/1000 | Train: Loss 0.001575 Accuracy : 1.000000 | Test: Loss 1.533476 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 527/1000 | Train: Loss 0.001559 Accuracy : 1.000000 | Test: Loss 1.531727 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 528/1000 | Train: Loss 0.001500 Accuracy : 1.000000 | Test: Loss 1.530347 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 529/1000 | Train: Loss 0.001418 Accuracy : 1.000000 | Test: Loss 1.526819 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 530/1000 | Train: Loss 0.001374 Accuracy : 1.000000 | Test: Loss 1.525732 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 531/1000 | Train: Loss 0.001351 Accuracy : 1.000000 | Test: Loss 1.525531 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 532/1000 | Train: Loss 0.001311 Accuracy : 1.000000 | Test: Loss 1.525410 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 533/1000 | Train: Loss 0.001348 Accuracy : 1.000000 | Test: Loss 1.525515 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 534/1000 | Train: Loss 0.001401 Accuracy : 1.000000 | Test: Loss 1.526353 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 535/1000 | Train: Loss 0.001446 Accuracy : 1.000000 | Test: Loss 1.527958 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 536/1000 | Train: Loss 0.001434 Accuracy : 1.000000 | Test: Loss 1.529684 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 537/1000 | Train: Loss 0.001416 Accuracy : 1.000000 | Test: Loss 1.531654 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 538/1000 | Train: Loss 0.001438 Accuracy : 1.000000 | Test: Loss 1.533502 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 539/1000 | Train: Loss 0.001440 Accuracy : 1.000000 | Test: Loss 1.533343 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 540/1000 | Train: Loss 0.001453 Accuracy : 1.000000 | Test: Loss 1.535133 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 541/1000 | Train: Loss 0.001412 Accuracy : 1.000000 | Test: Loss 1.536890 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 542/1000 | Train: Loss 0.001344 Accuracy : 1.000000 | Test: Loss 1.538059 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 543/1000 | Train: Loss 0.001360 Accuracy : 1.000000 | Test: Loss 1.540048 Accuracy : 0.745000\n",
            "\n",
            "| Epoch: 544/1000 | Train: Loss 0.001413 Accuracy : 1.000000 | Test: Loss 1.540292 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 545/1000 | Train: Loss 0.001353 Accuracy : 1.000000 | Test: Loss 1.538750 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 546/1000 | Train: Loss 0.001292 Accuracy : 1.000000 | Test: Loss 1.536935 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 547/1000 | Train: Loss 0.001271 Accuracy : 1.000000 | Test: Loss 1.534580 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 548/1000 | Train: Loss 0.001234 Accuracy : 1.000000 | Test: Loss 1.533107 Accuracy : 0.746000\n",
            "\n",
            "| Epoch: 549/1000 | Train: Loss 0.001217 Accuracy : 1.000000 | Test: Loss 1.532637 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 550/1000 | Train: Loss 0.001195 Accuracy : 1.000000 | Test: Loss 1.530271 Accuracy : 0.747000\n",
            "\n",
            "| Epoch: 551/1000 | Train: Loss 0.001175 Accuracy : 1.000000 | Test: Loss 1.530149 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 552/1000 | Train: Loss 0.001171 Accuracy : 1.000000 | Test: Loss 1.530444 Accuracy : 0.748000\n",
            "\n",
            "| Epoch: 553/1000 | Train: Loss 0.001116 Accuracy : 1.000000 | Test: Loss 1.530500 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 554/1000 | Train: Loss 0.001072 Accuracy : 1.000000 | Test: Loss 1.531442 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 555/1000 | Train: Loss 0.001031 Accuracy : 1.000000 | Test: Loss 1.531713 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 556/1000 | Train: Loss 0.000929 Accuracy : 1.000000 | Test: Loss 1.531607 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 557/1000 | Train: Loss 0.000857 Accuracy : 1.000000 | Test: Loss 1.530294 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 558/1000 | Train: Loss 0.000795 Accuracy : 1.000000 | Test: Loss 1.528399 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 559/1000 | Train: Loss 0.000745 Accuracy : 1.000000 | Test: Loss 1.526934 Accuracy : 0.749000\n",
            "\n",
            "| Epoch: 560/1000 | Train: Loss 0.000708 Accuracy : 1.000000 | Test: Loss 1.526510 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 561/1000 | Train: Loss 0.000664 Accuracy : 1.000000 | Test: Loss 1.523122 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 562/1000 | Train: Loss 0.000637 Accuracy : 1.000000 | Test: Loss 1.520122 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 563/1000 | Train: Loss 0.000605 Accuracy : 1.000000 | Test: Loss 1.517838 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 564/1000 | Train: Loss 0.000576 Accuracy : 1.000000 | Test: Loss 1.515387 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 565/1000 | Train: Loss 0.000572 Accuracy : 1.000000 | Test: Loss 1.514605 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 566/1000 | Train: Loss 0.000579 Accuracy : 1.000000 | Test: Loss 1.514441 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 567/1000 | Train: Loss 0.000582 Accuracy : 1.000000 | Test: Loss 1.515770 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 568/1000 | Train: Loss 0.000593 Accuracy : 1.000000 | Test: Loss 1.516784 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 569/1000 | Train: Loss 0.000596 Accuracy : 1.000000 | Test: Loss 1.516854 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 570/1000 | Train: Loss 0.000609 Accuracy : 1.000000 | Test: Loss 1.518099 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 571/1000 | Train: Loss 0.000611 Accuracy : 1.000000 | Test: Loss 1.517757 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 572/1000 | Train: Loss 0.000599 Accuracy : 1.000000 | Test: Loss 1.517410 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 573/1000 | Train: Loss 0.000600 Accuracy : 1.000000 | Test: Loss 1.516694 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 574/1000 | Train: Loss 0.000589 Accuracy : 1.000000 | Test: Loss 1.514465 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 575/1000 | Train: Loss 0.000577 Accuracy : 1.000000 | Test: Loss 1.511903 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 576/1000 | Train: Loss 0.000566 Accuracy : 1.000000 | Test: Loss 1.511531 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 577/1000 | Train: Loss 0.000559 Accuracy : 1.000000 | Test: Loss 1.510264 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 578/1000 | Train: Loss 0.000560 Accuracy : 1.000000 | Test: Loss 1.509902 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 579/1000 | Train: Loss 0.000562 Accuracy : 1.000000 | Test: Loss 1.509992 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 580/1000 | Train: Loss 0.000554 Accuracy : 1.000000 | Test: Loss 1.509695 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 581/1000 | Train: Loss 0.000545 Accuracy : 1.000000 | Test: Loss 1.510144 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 582/1000 | Train: Loss 0.000553 Accuracy : 1.000000 | Test: Loss 1.510869 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 583/1000 | Train: Loss 0.000562 Accuracy : 1.000000 | Test: Loss 1.510541 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 584/1000 | Train: Loss 0.000565 Accuracy : 1.000000 | Test: Loss 1.511569 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 585/1000 | Train: Loss 0.000553 Accuracy : 1.000000 | Test: Loss 1.510013 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 586/1000 | Train: Loss 0.000541 Accuracy : 1.000000 | Test: Loss 1.509658 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 587/1000 | Train: Loss 0.000516 Accuracy : 1.000000 | Test: Loss 1.507058 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 588/1000 | Train: Loss 0.000477 Accuracy : 1.000000 | Test: Loss 1.505333 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 589/1000 | Train: Loss 0.000463 Accuracy : 1.000000 | Test: Loss 1.504494 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 590/1000 | Train: Loss 0.000459 Accuracy : 1.000000 | Test: Loss 1.503395 Accuracy : 0.753000\n",
            "\n",
            "| Epoch: 591/1000 | Train: Loss 0.000455 Accuracy : 1.000000 | Test: Loss 1.503394 Accuracy : 0.753000\n",
            "\n",
            "| Epoch: 592/1000 | Train: Loss 0.000457 Accuracy : 1.000000 | Test: Loss 1.503401 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 593/1000 | Train: Loss 0.000438 Accuracy : 1.000000 | Test: Loss 1.503153 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 594/1000 | Train: Loss 0.000413 Accuracy : 1.000000 | Test: Loss 1.504032 Accuracy : 0.750000\n",
            "\n",
            "| Epoch: 595/1000 | Train: Loss 0.000399 Accuracy : 1.000000 | Test: Loss 1.502673 Accuracy : 0.751000\n",
            "\n",
            "| Epoch: 596/1000 | Train: Loss 0.000379 Accuracy : 1.000000 | Test: Loss 1.500566 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 597/1000 | Train: Loss 0.000373 Accuracy : 1.000000 | Test: Loss 1.500084 Accuracy : 0.752000\n",
            "\n",
            "| Epoch: 598/1000 | Train: Loss 0.000364 Accuracy : 1.000000 | Test: Loss 1.500116 Accuracy : 0.753000\n",
            "\n",
            "| Epoch: 599/1000 | Train: Loss 0.000346 Accuracy : 1.000000 | Test: Loss 1.501828 Accuracy : 0.753000\n",
            "\n",
            "| Epoch: 600/1000 | Train: Loss 0.000328 Accuracy : 1.000000 | Test: Loss 1.502414 Accuracy : 0.753000\n",
            "\n",
            "| Epoch: 601/1000 | Train: Loss 0.000313 Accuracy : 1.000000 | Test: Loss 1.502583 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 602/1000 | Train: Loss 0.000304 Accuracy : 1.000000 | Test: Loss 1.504284 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 603/1000 | Train: Loss 0.000300 Accuracy : 1.000000 | Test: Loss 1.505884 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 604/1000 | Train: Loss 0.000287 Accuracy : 1.000000 | Test: Loss 1.504207 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 605/1000 | Train: Loss 0.000286 Accuracy : 1.000000 | Test: Loss 1.504226 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 606/1000 | Train: Loss 0.000286 Accuracy : 1.000000 | Test: Loss 1.502947 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 607/1000 | Train: Loss 0.000282 Accuracy : 1.000000 | Test: Loss 1.503656 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 608/1000 | Train: Loss 0.000280 Accuracy : 1.000000 | Test: Loss 1.504153 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 609/1000 | Train: Loss 0.000279 Accuracy : 1.000000 | Test: Loss 1.503988 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 610/1000 | Train: Loss 0.000277 Accuracy : 1.000000 | Test: Loss 1.504149 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 611/1000 | Train: Loss 0.000278 Accuracy : 1.000000 | Test: Loss 1.505759 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 612/1000 | Train: Loss 0.000270 Accuracy : 1.000000 | Test: Loss 1.506829 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 613/1000 | Train: Loss 0.000265 Accuracy : 1.000000 | Test: Loss 1.507599 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 614/1000 | Train: Loss 0.000265 Accuracy : 1.000000 | Test: Loss 1.508530 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 615/1000 | Train: Loss 0.000262 Accuracy : 1.000000 | Test: Loss 1.508480 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 616/1000 | Train: Loss 0.000256 Accuracy : 1.000000 | Test: Loss 1.506598 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 617/1000 | Train: Loss 0.000254 Accuracy : 1.000000 | Test: Loss 1.504580 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 618/1000 | Train: Loss 0.000245 Accuracy : 1.000000 | Test: Loss 1.503421 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 619/1000 | Train: Loss 0.000238 Accuracy : 1.000000 | Test: Loss 1.501742 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 620/1000 | Train: Loss 0.000236 Accuracy : 1.000000 | Test: Loss 1.500839 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 621/1000 | Train: Loss 0.000232 Accuracy : 1.000000 | Test: Loss 1.501119 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 622/1000 | Train: Loss 0.000229 Accuracy : 1.000000 | Test: Loss 1.500864 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 623/1000 | Train: Loss 0.000228 Accuracy : 1.000000 | Test: Loss 1.499101 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 624/1000 | Train: Loss 0.000225 Accuracy : 1.000000 | Test: Loss 1.498590 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 625/1000 | Train: Loss 0.000216 Accuracy : 1.000000 | Test: Loss 1.497196 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 626/1000 | Train: Loss 0.000211 Accuracy : 1.000000 | Test: Loss 1.494666 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 627/1000 | Train: Loss 0.000200 Accuracy : 1.000000 | Test: Loss 1.492108 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 628/1000 | Train: Loss 0.000191 Accuracy : 1.000000 | Test: Loss 1.489868 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 629/1000 | Train: Loss 0.000187 Accuracy : 1.000000 | Test: Loss 1.488122 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 630/1000 | Train: Loss 0.000178 Accuracy : 1.000000 | Test: Loss 1.486013 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 631/1000 | Train: Loss 0.000176 Accuracy : 1.000000 | Test: Loss 1.483682 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 632/1000 | Train: Loss 0.000173 Accuracy : 1.000000 | Test: Loss 1.481664 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 633/1000 | Train: Loss 0.000171 Accuracy : 1.000000 | Test: Loss 1.481445 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 634/1000 | Train: Loss 0.000168 Accuracy : 1.000000 | Test: Loss 1.482460 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 635/1000 | Train: Loss 0.000161 Accuracy : 1.000000 | Test: Loss 1.480928 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 636/1000 | Train: Loss 0.000165 Accuracy : 1.000000 | Test: Loss 1.481471 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 637/1000 | Train: Loss 0.000163 Accuracy : 1.000000 | Test: Loss 1.480072 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 638/1000 | Train: Loss 0.000162 Accuracy : 1.000000 | Test: Loss 1.479965 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 639/1000 | Train: Loss 0.000162 Accuracy : 1.000000 | Test: Loss 1.479415 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 640/1000 | Train: Loss 0.000166 Accuracy : 1.000000 | Test: Loss 1.481433 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 641/1000 | Train: Loss 0.000171 Accuracy : 1.000000 | Test: Loss 1.484461 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 642/1000 | Train: Loss 0.000178 Accuracy : 1.000000 | Test: Loss 1.484504 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 643/1000 | Train: Loss 0.000185 Accuracy : 1.000000 | Test: Loss 1.486797 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 644/1000 | Train: Loss 0.000190 Accuracy : 1.000000 | Test: Loss 1.489186 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 645/1000 | Train: Loss 0.000188 Accuracy : 1.000000 | Test: Loss 1.491257 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 646/1000 | Train: Loss 0.000184 Accuracy : 1.000000 | Test: Loss 1.493124 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 647/1000 | Train: Loss 0.000184 Accuracy : 1.000000 | Test: Loss 1.493481 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 648/1000 | Train: Loss 0.000181 Accuracy : 1.000000 | Test: Loss 1.493504 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 649/1000 | Train: Loss 0.000183 Accuracy : 1.000000 | Test: Loss 1.495029 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 650/1000 | Train: Loss 0.000188 Accuracy : 1.000000 | Test: Loss 1.496682 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 651/1000 | Train: Loss 0.000189 Accuracy : 1.000000 | Test: Loss 1.497942 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 652/1000 | Train: Loss 0.000193 Accuracy : 1.000000 | Test: Loss 1.500217 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 653/1000 | Train: Loss 0.000194 Accuracy : 1.000000 | Test: Loss 1.501465 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 654/1000 | Train: Loss 0.000194 Accuracy : 1.000000 | Test: Loss 1.502479 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 655/1000 | Train: Loss 0.000194 Accuracy : 1.000000 | Test: Loss 1.504621 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 656/1000 | Train: Loss 0.000194 Accuracy : 1.000000 | Test: Loss 1.505740 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 657/1000 | Train: Loss 0.000192 Accuracy : 1.000000 | Test: Loss 1.505750 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 658/1000 | Train: Loss 0.000181 Accuracy : 1.000000 | Test: Loss 1.506302 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 659/1000 | Train: Loss 0.000177 Accuracy : 1.000000 | Test: Loss 1.505888 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 660/1000 | Train: Loss 0.000169 Accuracy : 1.000000 | Test: Loss 1.503941 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 661/1000 | Train: Loss 0.000165 Accuracy : 1.000000 | Test: Loss 1.502394 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 662/1000 | Train: Loss 0.000164 Accuracy : 1.000000 | Test: Loss 1.501665 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 663/1000 | Train: Loss 0.000163 Accuracy : 1.000000 | Test: Loss 1.500177 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 664/1000 | Train: Loss 0.000162 Accuracy : 1.000000 | Test: Loss 1.501068 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 665/1000 | Train: Loss 0.000163 Accuracy : 1.000000 | Test: Loss 1.500950 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 666/1000 | Train: Loss 0.000159 Accuracy : 1.000000 | Test: Loss 1.501206 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 667/1000 | Train: Loss 0.000155 Accuracy : 1.000000 | Test: Loss 1.501380 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 668/1000 | Train: Loss 0.000153 Accuracy : 1.000000 | Test: Loss 1.499878 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 669/1000 | Train: Loss 0.000153 Accuracy : 1.000000 | Test: Loss 1.498315 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 670/1000 | Train: Loss 0.000160 Accuracy : 1.000000 | Test: Loss 1.500098 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 671/1000 | Train: Loss 0.000157 Accuracy : 1.000000 | Test: Loss 1.501308 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 672/1000 | Train: Loss 0.000150 Accuracy : 1.000000 | Test: Loss 1.501951 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 673/1000 | Train: Loss 0.000150 Accuracy : 1.000000 | Test: Loss 1.501240 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 674/1000 | Train: Loss 0.000150 Accuracy : 1.000000 | Test: Loss 1.502805 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 675/1000 | Train: Loss 0.000146 Accuracy : 1.000000 | Test: Loss 1.502971 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 676/1000 | Train: Loss 0.000147 Accuracy : 1.000000 | Test: Loss 1.503251 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 677/1000 | Train: Loss 0.000149 Accuracy : 1.000000 | Test: Loss 1.505352 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 678/1000 | Train: Loss 0.000149 Accuracy : 1.000000 | Test: Loss 1.507327 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 679/1000 | Train: Loss 0.000143 Accuracy : 1.000000 | Test: Loss 1.509761 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 680/1000 | Train: Loss 0.000138 Accuracy : 1.000000 | Test: Loss 1.512294 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 681/1000 | Train: Loss 0.000135 Accuracy : 1.000000 | Test: Loss 1.514352 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 682/1000 | Train: Loss 0.000135 Accuracy : 1.000000 | Test: Loss 1.516881 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 683/1000 | Train: Loss 0.000131 Accuracy : 1.000000 | Test: Loss 1.517274 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 684/1000 | Train: Loss 0.000130 Accuracy : 1.000000 | Test: Loss 1.518874 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 685/1000 | Train: Loss 0.000128 Accuracy : 1.000000 | Test: Loss 1.517039 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 686/1000 | Train: Loss 0.000129 Accuracy : 1.000000 | Test: Loss 1.516682 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 687/1000 | Train: Loss 0.000130 Accuracy : 1.000000 | Test: Loss 1.516347 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 688/1000 | Train: Loss 0.000128 Accuracy : 1.000000 | Test: Loss 1.516540 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 689/1000 | Train: Loss 0.000125 Accuracy : 1.000000 | Test: Loss 1.516241 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 690/1000 | Train: Loss 0.000120 Accuracy : 1.000000 | Test: Loss 1.516952 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 691/1000 | Train: Loss 0.000114 Accuracy : 1.000000 | Test: Loss 1.517316 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 692/1000 | Train: Loss 0.000108 Accuracy : 1.000000 | Test: Loss 1.516418 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 693/1000 | Train: Loss 0.000106 Accuracy : 1.000000 | Test: Loss 1.515490 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 694/1000 | Train: Loss 0.000104 Accuracy : 1.000000 | Test: Loss 1.514904 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 695/1000 | Train: Loss 0.000104 Accuracy : 1.000000 | Test: Loss 1.514649 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 696/1000 | Train: Loss 0.000104 Accuracy : 1.000000 | Test: Loss 1.514187 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 697/1000 | Train: Loss 0.000101 Accuracy : 1.000000 | Test: Loss 1.514983 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 698/1000 | Train: Loss 0.000099 Accuracy : 1.000000 | Test: Loss 1.514245 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 699/1000 | Train: Loss 0.000102 Accuracy : 1.000000 | Test: Loss 1.515095 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 700/1000 | Train: Loss 0.000101 Accuracy : 1.000000 | Test: Loss 1.514915 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 701/1000 | Train: Loss 0.000102 Accuracy : 1.000000 | Test: Loss 1.515925 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 702/1000 | Train: Loss 0.000104 Accuracy : 1.000000 | Test: Loss 1.516138 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 703/1000 | Train: Loss 0.000104 Accuracy : 1.000000 | Test: Loss 1.515829 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 704/1000 | Train: Loss 0.000102 Accuracy : 1.000000 | Test: Loss 1.516276 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 705/1000 | Train: Loss 0.000097 Accuracy : 1.000000 | Test: Loss 1.515958 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 706/1000 | Train: Loss 0.000093 Accuracy : 1.000000 | Test: Loss 1.514485 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 707/1000 | Train: Loss 0.000088 Accuracy : 1.000000 | Test: Loss 1.515559 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 708/1000 | Train: Loss 0.000086 Accuracy : 1.000000 | Test: Loss 1.513920 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 709/1000 | Train: Loss 0.000087 Accuracy : 1.000000 | Test: Loss 1.513041 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 710/1000 | Train: Loss 0.000083 Accuracy : 1.000000 | Test: Loss 1.511837 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 711/1000 | Train: Loss 0.000082 Accuracy : 1.000000 | Test: Loss 1.512226 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 712/1000 | Train: Loss 0.000081 Accuracy : 1.000000 | Test: Loss 1.513301 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 713/1000 | Train: Loss 0.000081 Accuracy : 1.000000 | Test: Loss 1.514519 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 714/1000 | Train: Loss 0.000080 Accuracy : 1.000000 | Test: Loss 1.514638 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 715/1000 | Train: Loss 0.000081 Accuracy : 1.000000 | Test: Loss 1.515621 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 716/1000 | Train: Loss 0.000081 Accuracy : 1.000000 | Test: Loss 1.514705 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 717/1000 | Train: Loss 0.000084 Accuracy : 1.000000 | Test: Loss 1.514800 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 718/1000 | Train: Loss 0.000087 Accuracy : 1.000000 | Test: Loss 1.515145 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 719/1000 | Train: Loss 0.000090 Accuracy : 1.000000 | Test: Loss 1.513771 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 720/1000 | Train: Loss 0.000091 Accuracy : 1.000000 | Test: Loss 1.511994 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 721/1000 | Train: Loss 0.000091 Accuracy : 1.000000 | Test: Loss 1.509371 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 722/1000 | Train: Loss 0.000094 Accuracy : 1.000000 | Test: Loss 1.507338 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 723/1000 | Train: Loss 0.000097 Accuracy : 1.000000 | Test: Loss 1.506935 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 724/1000 | Train: Loss 0.000100 Accuracy : 1.000000 | Test: Loss 1.506515 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 725/1000 | Train: Loss 0.000103 Accuracy : 1.000000 | Test: Loss 1.504564 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 726/1000 | Train: Loss 0.000104 Accuracy : 1.000000 | Test: Loss 1.503801 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 727/1000 | Train: Loss 0.000103 Accuracy : 1.000000 | Test: Loss 1.504414 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 728/1000 | Train: Loss 0.000100 Accuracy : 1.000000 | Test: Loss 1.505750 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 729/1000 | Train: Loss 0.000096 Accuracy : 1.000000 | Test: Loss 1.505606 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 730/1000 | Train: Loss 0.000095 Accuracy : 1.000000 | Test: Loss 1.504849 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 731/1000 | Train: Loss 0.000095 Accuracy : 1.000000 | Test: Loss 1.506307 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 732/1000 | Train: Loss 0.000094 Accuracy : 1.000000 | Test: Loss 1.506948 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 733/1000 | Train: Loss 0.000090 Accuracy : 1.000000 | Test: Loss 1.507758 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 734/1000 | Train: Loss 0.000088 Accuracy : 1.000000 | Test: Loss 1.507960 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 735/1000 | Train: Loss 0.000086 Accuracy : 1.000000 | Test: Loss 1.507175 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 736/1000 | Train: Loss 0.000085 Accuracy : 1.000000 | Test: Loss 1.505695 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 737/1000 | Train: Loss 0.000083 Accuracy : 1.000000 | Test: Loss 1.503289 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 738/1000 | Train: Loss 0.000084 Accuracy : 1.000000 | Test: Loss 1.501563 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 739/1000 | Train: Loss 0.000085 Accuracy : 1.000000 | Test: Loss 1.501405 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 740/1000 | Train: Loss 0.000087 Accuracy : 1.000000 | Test: Loss 1.502099 Accuracy : 0.763000\n",
            "\n",
            "| Epoch: 741/1000 | Train: Loss 0.000088 Accuracy : 1.000000 | Test: Loss 1.503862 Accuracy : 0.763000\n",
            "\n",
            "| Epoch: 742/1000 | Train: Loss 0.000088 Accuracy : 1.000000 | Test: Loss 1.504545 Accuracy : 0.763000\n",
            "\n",
            "| Epoch: 743/1000 | Train: Loss 0.000089 Accuracy : 1.000000 | Test: Loss 1.504942 Accuracy : 0.763000\n",
            "\n",
            "| Epoch: 744/1000 | Train: Loss 0.000088 Accuracy : 1.000000 | Test: Loss 1.505635 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 745/1000 | Train: Loss 0.000087 Accuracy : 1.000000 | Test: Loss 1.506997 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 746/1000 | Train: Loss 0.000086 Accuracy : 1.000000 | Test: Loss 1.507401 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 747/1000 | Train: Loss 0.000084 Accuracy : 1.000000 | Test: Loss 1.509274 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 748/1000 | Train: Loss 0.000083 Accuracy : 1.000000 | Test: Loss 1.509366 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 749/1000 | Train: Loss 0.000083 Accuracy : 1.000000 | Test: Loss 1.511822 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 750/1000 | Train: Loss 0.000081 Accuracy : 1.000000 | Test: Loss 1.512048 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 751/1000 | Train: Loss 0.000079 Accuracy : 1.000000 | Test: Loss 1.512502 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 752/1000 | Train: Loss 0.000077 Accuracy : 1.000000 | Test: Loss 1.513963 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 753/1000 | Train: Loss 0.000079 Accuracy : 1.000000 | Test: Loss 1.515141 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 754/1000 | Train: Loss 0.000079 Accuracy : 1.000000 | Test: Loss 1.514778 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 755/1000 | Train: Loss 0.000081 Accuracy : 1.000000 | Test: Loss 1.513678 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 756/1000 | Train: Loss 0.000081 Accuracy : 1.000000 | Test: Loss 1.513353 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 757/1000 | Train: Loss 0.000084 Accuracy : 1.000000 | Test: Loss 1.512825 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 758/1000 | Train: Loss 0.000086 Accuracy : 1.000000 | Test: Loss 1.511099 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 759/1000 | Train: Loss 0.000087 Accuracy : 1.000000 | Test: Loss 1.509791 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 760/1000 | Train: Loss 0.000087 Accuracy : 1.000000 | Test: Loss 1.510490 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 761/1000 | Train: Loss 0.000085 Accuracy : 1.000000 | Test: Loss 1.511431 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 762/1000 | Train: Loss 0.000086 Accuracy : 1.000000 | Test: Loss 1.512318 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 763/1000 | Train: Loss 0.000085 Accuracy : 1.000000 | Test: Loss 1.511798 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 764/1000 | Train: Loss 0.000086 Accuracy : 1.000000 | Test: Loss 1.512652 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 765/1000 | Train: Loss 0.000088 Accuracy : 1.000000 | Test: Loss 1.513073 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 766/1000 | Train: Loss 0.000090 Accuracy : 1.000000 | Test: Loss 1.514989 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 767/1000 | Train: Loss 0.000089 Accuracy : 1.000000 | Test: Loss 1.516275 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 768/1000 | Train: Loss 0.000091 Accuracy : 1.000000 | Test: Loss 1.517226 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 769/1000 | Train: Loss 0.000092 Accuracy : 1.000000 | Test: Loss 1.517986 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 770/1000 | Train: Loss 0.000093 Accuracy : 1.000000 | Test: Loss 1.519608 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 771/1000 | Train: Loss 0.000095 Accuracy : 1.000000 | Test: Loss 1.520739 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 772/1000 | Train: Loss 0.000099 Accuracy : 1.000000 | Test: Loss 1.521460 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 773/1000 | Train: Loss 0.000099 Accuracy : 1.000000 | Test: Loss 1.521343 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 774/1000 | Train: Loss 0.000098 Accuracy : 1.000000 | Test: Loss 1.522609 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 775/1000 | Train: Loss 0.000094 Accuracy : 1.000000 | Test: Loss 1.521976 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 776/1000 | Train: Loss 0.000092 Accuracy : 1.000000 | Test: Loss 1.518728 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 777/1000 | Train: Loss 0.000092 Accuracy : 1.000000 | Test: Loss 1.515778 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 778/1000 | Train: Loss 0.000091 Accuracy : 1.000000 | Test: Loss 1.514068 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 779/1000 | Train: Loss 0.000089 Accuracy : 1.000000 | Test: Loss 1.512642 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 780/1000 | Train: Loss 0.000086 Accuracy : 1.000000 | Test: Loss 1.509911 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 781/1000 | Train: Loss 0.000083 Accuracy : 1.000000 | Test: Loss 1.507806 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 782/1000 | Train: Loss 0.000082 Accuracy : 1.000000 | Test: Loss 1.506789 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 783/1000 | Train: Loss 0.000081 Accuracy : 1.000000 | Test: Loss 1.506734 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 784/1000 | Train: Loss 0.000080 Accuracy : 1.000000 | Test: Loss 1.506927 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 785/1000 | Train: Loss 0.000079 Accuracy : 1.000000 | Test: Loss 1.506384 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 786/1000 | Train: Loss 0.000078 Accuracy : 1.000000 | Test: Loss 1.506165 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 787/1000 | Train: Loss 0.000078 Accuracy : 1.000000 | Test: Loss 1.506123 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 788/1000 | Train: Loss 0.000075 Accuracy : 1.000000 | Test: Loss 1.505961 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 789/1000 | Train: Loss 0.000074 Accuracy : 1.000000 | Test: Loss 1.505651 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 790/1000 | Train: Loss 0.000074 Accuracy : 1.000000 | Test: Loss 1.507419 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 791/1000 | Train: Loss 0.000074 Accuracy : 1.000000 | Test: Loss 1.508718 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 792/1000 | Train: Loss 0.000074 Accuracy : 1.000000 | Test: Loss 1.509000 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 793/1000 | Train: Loss 0.000074 Accuracy : 1.000000 | Test: Loss 1.509844 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 794/1000 | Train: Loss 0.000076 Accuracy : 1.000000 | Test: Loss 1.509298 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 795/1000 | Train: Loss 0.000076 Accuracy : 1.000000 | Test: Loss 1.507713 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 796/1000 | Train: Loss 0.000077 Accuracy : 1.000000 | Test: Loss 1.507162 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 797/1000 | Train: Loss 0.000077 Accuracy : 1.000000 | Test: Loss 1.506516 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 798/1000 | Train: Loss 0.000075 Accuracy : 1.000000 | Test: Loss 1.507699 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 799/1000 | Train: Loss 0.000075 Accuracy : 1.000000 | Test: Loss 1.509447 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 800/1000 | Train: Loss 0.000075 Accuracy : 1.000000 | Test: Loss 1.509821 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 801/1000 | Train: Loss 0.000074 Accuracy : 1.000000 | Test: Loss 1.510603 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 802/1000 | Train: Loss 0.000075 Accuracy : 1.000000 | Test: Loss 1.511133 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 803/1000 | Train: Loss 0.000076 Accuracy : 1.000000 | Test: Loss 1.510911 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 804/1000 | Train: Loss 0.000075 Accuracy : 1.000000 | Test: Loss 1.509222 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 805/1000 | Train: Loss 0.000072 Accuracy : 1.000000 | Test: Loss 1.509225 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 806/1000 | Train: Loss 0.000070 Accuracy : 1.000000 | Test: Loss 1.508670 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 807/1000 | Train: Loss 0.000070 Accuracy : 1.000000 | Test: Loss 1.509439 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 808/1000 | Train: Loss 0.000069 Accuracy : 1.000000 | Test: Loss 1.510507 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 809/1000 | Train: Loss 0.000069 Accuracy : 1.000000 | Test: Loss 1.511272 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 810/1000 | Train: Loss 0.000067 Accuracy : 1.000000 | Test: Loss 1.511307 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 811/1000 | Train: Loss 0.000067 Accuracy : 1.000000 | Test: Loss 1.511268 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 812/1000 | Train: Loss 0.000068 Accuracy : 1.000000 | Test: Loss 1.510775 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 813/1000 | Train: Loss 0.000067 Accuracy : 1.000000 | Test: Loss 1.509465 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 814/1000 | Train: Loss 0.000066 Accuracy : 1.000000 | Test: Loss 1.509840 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 815/1000 | Train: Loss 0.000065 Accuracy : 1.000000 | Test: Loss 1.510946 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 816/1000 | Train: Loss 0.000066 Accuracy : 1.000000 | Test: Loss 1.513157 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 817/1000 | Train: Loss 0.000066 Accuracy : 1.000000 | Test: Loss 1.514775 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 818/1000 | Train: Loss 0.000065 Accuracy : 1.000000 | Test: Loss 1.516043 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 819/1000 | Train: Loss 0.000062 Accuracy : 1.000000 | Test: Loss 1.518497 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 820/1000 | Train: Loss 0.000059 Accuracy : 1.000000 | Test: Loss 1.520260 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 821/1000 | Train: Loss 0.000058 Accuracy : 1.000000 | Test: Loss 1.522282 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 822/1000 | Train: Loss 0.000060 Accuracy : 1.000000 | Test: Loss 1.525261 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 823/1000 | Train: Loss 0.000061 Accuracy : 1.000000 | Test: Loss 1.527410 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 824/1000 | Train: Loss 0.000063 Accuracy : 1.000000 | Test: Loss 1.528645 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 825/1000 | Train: Loss 0.000063 Accuracy : 1.000000 | Test: Loss 1.529804 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 826/1000 | Train: Loss 0.000066 Accuracy : 1.000000 | Test: Loss 1.530852 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 827/1000 | Train: Loss 0.000066 Accuracy : 1.000000 | Test: Loss 1.530069 Accuracy : 0.754000\n",
            "\n",
            "| Epoch: 828/1000 | Train: Loss 0.000066 Accuracy : 1.000000 | Test: Loss 1.528217 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 829/1000 | Train: Loss 0.000065 Accuracy : 1.000000 | Test: Loss 1.528189 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 830/1000 | Train: Loss 0.000063 Accuracy : 1.000000 | Test: Loss 1.528634 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 831/1000 | Train: Loss 0.000065 Accuracy : 1.000000 | Test: Loss 1.527709 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 832/1000 | Train: Loss 0.000066 Accuracy : 1.000000 | Test: Loss 1.528324 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 833/1000 | Train: Loss 0.000065 Accuracy : 1.000000 | Test: Loss 1.528596 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 834/1000 | Train: Loss 0.000064 Accuracy : 1.000000 | Test: Loss 1.527905 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 835/1000 | Train: Loss 0.000064 Accuracy : 1.000000 | Test: Loss 1.530091 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 836/1000 | Train: Loss 0.000063 Accuracy : 1.000000 | Test: Loss 1.531290 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 837/1000 | Train: Loss 0.000063 Accuracy : 1.000000 | Test: Loss 1.532464 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 838/1000 | Train: Loss 0.000063 Accuracy : 1.000000 | Test: Loss 1.533678 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 839/1000 | Train: Loss 0.000061 Accuracy : 1.000000 | Test: Loss 1.532070 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 840/1000 | Train: Loss 0.000058 Accuracy : 1.000000 | Test: Loss 1.531955 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 841/1000 | Train: Loss 0.000055 Accuracy : 1.000000 | Test: Loss 1.532187 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 842/1000 | Train: Loss 0.000053 Accuracy : 1.000000 | Test: Loss 1.532537 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 843/1000 | Train: Loss 0.000052 Accuracy : 1.000000 | Test: Loss 1.531905 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 844/1000 | Train: Loss 0.000053 Accuracy : 1.000000 | Test: Loss 1.531590 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 845/1000 | Train: Loss 0.000052 Accuracy : 1.000000 | Test: Loss 1.532751 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 846/1000 | Train: Loss 0.000052 Accuracy : 1.000000 | Test: Loss 1.533306 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 847/1000 | Train: Loss 0.000051 Accuracy : 1.000000 | Test: Loss 1.534972 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 848/1000 | Train: Loss 0.000051 Accuracy : 1.000000 | Test: Loss 1.538005 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 849/1000 | Train: Loss 0.000051 Accuracy : 1.000000 | Test: Loss 1.538493 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 850/1000 | Train: Loss 0.000050 Accuracy : 1.000000 | Test: Loss 1.539690 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 851/1000 | Train: Loss 0.000051 Accuracy : 1.000000 | Test: Loss 1.540717 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 852/1000 | Train: Loss 0.000051 Accuracy : 1.000000 | Test: Loss 1.542831 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 853/1000 | Train: Loss 0.000050 Accuracy : 1.000000 | Test: Loss 1.541732 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 854/1000 | Train: Loss 0.000047 Accuracy : 1.000000 | Test: Loss 1.541288 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 855/1000 | Train: Loss 0.000044 Accuracy : 1.000000 | Test: Loss 1.540888 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 856/1000 | Train: Loss 0.000042 Accuracy : 1.000000 | Test: Loss 1.540515 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 857/1000 | Train: Loss 0.000040 Accuracy : 1.000000 | Test: Loss 1.540050 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 858/1000 | Train: Loss 0.000039 Accuracy : 1.000000 | Test: Loss 1.539643 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 859/1000 | Train: Loss 0.000038 Accuracy : 1.000000 | Test: Loss 1.542323 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 860/1000 | Train: Loss 0.000038 Accuracy : 1.000000 | Test: Loss 1.543247 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 861/1000 | Train: Loss 0.000039 Accuracy : 1.000000 | Test: Loss 1.543827 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 862/1000 | Train: Loss 0.000039 Accuracy : 1.000000 | Test: Loss 1.545490 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 863/1000 | Train: Loss 0.000040 Accuracy : 1.000000 | Test: Loss 1.547470 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 864/1000 | Train: Loss 0.000040 Accuracy : 1.000000 | Test: Loss 1.548717 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 865/1000 | Train: Loss 0.000040 Accuracy : 1.000000 | Test: Loss 1.549720 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 866/1000 | Train: Loss 0.000039 Accuracy : 1.000000 | Test: Loss 1.551278 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 867/1000 | Train: Loss 0.000039 Accuracy : 1.000000 | Test: Loss 1.552728 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 868/1000 | Train: Loss 0.000038 Accuracy : 1.000000 | Test: Loss 1.553673 Accuracy : 0.755000\n",
            "\n",
            "| Epoch: 869/1000 | Train: Loss 0.000037 Accuracy : 1.000000 | Test: Loss 1.554854 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 870/1000 | Train: Loss 0.000036 Accuracy : 1.000000 | Test: Loss 1.556713 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 871/1000 | Train: Loss 0.000036 Accuracy : 1.000000 | Test: Loss 1.556538 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 872/1000 | Train: Loss 0.000034 Accuracy : 1.000000 | Test: Loss 1.556195 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 873/1000 | Train: Loss 0.000035 Accuracy : 1.000000 | Test: Loss 1.555759 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 874/1000 | Train: Loss 0.000035 Accuracy : 1.000000 | Test: Loss 1.554585 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 875/1000 | Train: Loss 0.000035 Accuracy : 1.000000 | Test: Loss 1.553029 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 876/1000 | Train: Loss 0.000034 Accuracy : 1.000000 | Test: Loss 1.551446 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 877/1000 | Train: Loss 0.000034 Accuracy : 1.000000 | Test: Loss 1.549569 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 878/1000 | Train: Loss 0.000032 Accuracy : 1.000000 | Test: Loss 1.547581 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 879/1000 | Train: Loss 0.000031 Accuracy : 1.000000 | Test: Loss 1.546911 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 880/1000 | Train: Loss 0.000031 Accuracy : 1.000000 | Test: Loss 1.545912 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 881/1000 | Train: Loss 0.000031 Accuracy : 1.000000 | Test: Loss 1.545585 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 882/1000 | Train: Loss 0.000032 Accuracy : 1.000000 | Test: Loss 1.547456 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 883/1000 | Train: Loss 0.000032 Accuracy : 1.000000 | Test: Loss 1.550285 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 884/1000 | Train: Loss 0.000032 Accuracy : 1.000000 | Test: Loss 1.552876 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 885/1000 | Train: Loss 0.000032 Accuracy : 1.000000 | Test: Loss 1.553935 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 886/1000 | Train: Loss 0.000031 Accuracy : 1.000000 | Test: Loss 1.554407 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 887/1000 | Train: Loss 0.000031 Accuracy : 1.000000 | Test: Loss 1.555095 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 888/1000 | Train: Loss 0.000030 Accuracy : 1.000000 | Test: Loss 1.556241 Accuracy : 0.756000\n",
            "\n",
            "| Epoch: 889/1000 | Train: Loss 0.000029 Accuracy : 1.000000 | Test: Loss 1.556572 Accuracy : 0.757000\n",
            "\n",
            "| Epoch: 890/1000 | Train: Loss 0.000028 Accuracy : 1.000000 | Test: Loss 1.556210 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 891/1000 | Train: Loss 0.000027 Accuracy : 1.000000 | Test: Loss 1.554429 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 892/1000 | Train: Loss 0.000026 Accuracy : 1.000000 | Test: Loss 1.553451 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 893/1000 | Train: Loss 0.000026 Accuracy : 1.000000 | Test: Loss 1.552359 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 894/1000 | Train: Loss 0.000025 Accuracy : 1.000000 | Test: Loss 1.551925 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 895/1000 | Train: Loss 0.000025 Accuracy : 1.000000 | Test: Loss 1.550793 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 896/1000 | Train: Loss 0.000024 Accuracy : 1.000000 | Test: Loss 1.550398 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 897/1000 | Train: Loss 0.000024 Accuracy : 1.000000 | Test: Loss 1.550822 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 898/1000 | Train: Loss 0.000025 Accuracy : 1.000000 | Test: Loss 1.550534 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 899/1000 | Train: Loss 0.000025 Accuracy : 1.000000 | Test: Loss 1.551065 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 900/1000 | Train: Loss 0.000025 Accuracy : 1.000000 | Test: Loss 1.551114 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 901/1000 | Train: Loss 0.000025 Accuracy : 1.000000 | Test: Loss 1.549717 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 902/1000 | Train: Loss 0.000024 Accuracy : 1.000000 | Test: Loss 1.548492 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 903/1000 | Train: Loss 0.000023 Accuracy : 1.000000 | Test: Loss 1.547456 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 904/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.546093 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 905/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.542775 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 906/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.539714 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 907/1000 | Train: Loss 0.000020 Accuracy : 1.000000 | Test: Loss 1.538320 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 908/1000 | Train: Loss 0.000020 Accuracy : 1.000000 | Test: Loss 1.537258 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 909/1000 | Train: Loss 0.000020 Accuracy : 1.000000 | Test: Loss 1.536972 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 910/1000 | Train: Loss 0.000020 Accuracy : 1.000000 | Test: Loss 1.536088 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 911/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.536122 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 912/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.536435 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 913/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.535624 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 914/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.534565 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 915/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.533978 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 916/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.532488 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 917/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.534891 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 918/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.533779 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 919/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.534428 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 920/1000 | Train: Loss 0.000017 Accuracy : 1.000000 | Test: Loss 1.534569 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 921/1000 | Train: Loss 0.000017 Accuracy : 1.000000 | Test: Loss 1.535607 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 922/1000 | Train: Loss 0.000017 Accuracy : 1.000000 | Test: Loss 1.535005 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 923/1000 | Train: Loss 0.000017 Accuracy : 1.000000 | Test: Loss 1.535105 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 924/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.535751 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 925/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.539043 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 926/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.541034 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 927/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.543100 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 928/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.545363 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 929/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.546068 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 930/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.546511 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 931/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.546061 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 932/1000 | Train: Loss 0.000020 Accuracy : 1.000000 | Test: Loss 1.546037 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 933/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.544509 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 934/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.543529 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 935/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.544749 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 936/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.544499 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 937/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.544556 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 938/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.544249 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 939/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.544871 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 940/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.544407 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 941/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.544773 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 942/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.545467 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 943/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.546476 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 944/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.547215 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 945/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.547679 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 946/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.547734 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 947/1000 | Train: Loss 0.000023 Accuracy : 1.000000 | Test: Loss 1.546754 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 948/1000 | Train: Loss 0.000023 Accuracy : 1.000000 | Test: Loss 1.544801 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 949/1000 | Train: Loss 0.000023 Accuracy : 1.000000 | Test: Loss 1.543799 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 950/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.543004 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 951/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.542129 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 952/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.541884 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 953/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.541285 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 954/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.540792 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 955/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.540885 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 956/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.540828 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 957/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.541370 Accuracy : 0.763000\n",
            "\n",
            "| Epoch: 958/1000 | Train: Loss 0.000022 Accuracy : 1.000000 | Test: Loss 1.542954 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 959/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.543879 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 960/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.544627 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 961/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.546283 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 962/1000 | Train: Loss 0.000021 Accuracy : 1.000000 | Test: Loss 1.546094 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 963/1000 | Train: Loss 0.000020 Accuracy : 1.000000 | Test: Loss 1.544920 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 964/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.543509 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 965/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.542900 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 966/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.542489 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 967/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.541667 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 968/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.542845 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 969/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.542906 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 970/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.542723 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 971/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.542021 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 972/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.541330 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 973/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.541453 Accuracy : 0.758000\n",
            "\n",
            "| Epoch: 974/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.540998 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 975/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.540249 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 976/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.539554 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 977/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.539511 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 978/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.540340 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 979/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.540831 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 980/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.539483 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 981/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.537436 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 982/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.536564 Accuracy : 0.762000\n",
            "\n",
            "| Epoch: 983/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.538276 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 984/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.538572 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 985/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.538786 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 986/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.539187 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 987/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.539493 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 988/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.539072 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 989/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.538702 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 990/1000 | Train: Loss 0.000019 Accuracy : 1.000000 | Test: Loss 1.538227 Accuracy : 0.759000\n",
            "\n",
            "| Epoch: 991/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.537800 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 992/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.537816 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 993/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.536038 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 994/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.535507 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 995/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.536467 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 996/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.537446 Accuracy : 0.760000\n",
            "\n",
            "| Epoch: 997/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.537852 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 998/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.538489 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 999/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.537800 Accuracy : 0.761000\n",
            "\n",
            "| Epoch: 1000/1000 | Train: Loss 0.000018 Accuracy : 1.000000 | Test: Loss 1.539110 Accuracy : 0.761000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f58155d0828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAHgCAYAAACb58plAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "974TCN9hZqDE",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}